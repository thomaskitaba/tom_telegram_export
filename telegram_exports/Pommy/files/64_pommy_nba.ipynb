{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 0: Enviroment Setup"
      ],
      "metadata": {
        "id": "htr97dhz3DvE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QPoOxJGCzLsu",
        "outputId": "3b51c7b8-3cf2-48fc-c092-71fa4b3dede1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pgmpy\n",
            "  Downloading pgmpy-1.0.0-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Collecting nba_api\n",
            "  Downloading nba_api-1.10.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pgmpy) (2.8.0+cu126)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pgmpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pgmpy) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from pgmpy) (3.4.0)\n",
            "Collecting pyro-ppl (from pgmpy)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl->pgmpy)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->pgmpy) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pgmpy) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pgmpy) (3.0.3)\n",
            "Downloading pgmpy-1.0.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nba_api-1.10.2-py3-none-any.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m287.0/287.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyro-api, fuzzywuzzy, rapidfuzz, Levenshtein, python-Levenshtein, nba_api, pyro-ppl, pgmpy\n",
            "Successfully installed Levenshtein-0.27.1 fuzzywuzzy-0.18.0 nba_api-1.10.2 pgmpy-1.0.0 pyro-api-0.1.2 pyro-ppl-1.9.1 python-Levenshtein-0.27.1 rapidfuzz-3.14.1\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install pgmpy pandas numpy matplotlib seaborn networkx fuzzywuzzy python-Levenshtein kaggle nba_api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All packages installed and imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzSZBTaP1bCk",
        "outputId": "68ecec08-9e89-450f-b633-7cccc9f5ca2b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All packages installed and imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1: Data Acquistion & Problem Formalization"
      ],
      "metadata": {
        "id": "uXSCkKWm2-3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1.1: Install NBA API and Get Data\n"
      ],
      "metadata": {
        "id": "GJA6LCy83H_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üöÄ GETTING REAL NBA LINEUP DATA FROM OFFICIAL NBA API...\")\n",
        "\n",
        "# Install nba_api\n",
        "!pip install nba_api\n",
        "\n",
        "from nba_api.stats.endpoints import teamdashlineups\n",
        "from nba_api.stats.static import teams\n",
        "import pandas as pd\n",
        "\n",
        "# Get all NBA teams\n",
        "nba_teams = teams.get_teams()\n",
        "\n",
        "# Create team dictionary\n",
        "team_dict = {}\n",
        "for team in nba_teams:\n",
        "    team_name = team['full_name']\n",
        "    team_id = team['id']\n",
        "    team_dict[team_name] = team_id\n",
        "\n",
        "print(f\"‚úÖ Found {len(team_dict)} NBA teams\")\n",
        "\n",
        "# Function to get lineups for a team\n",
        "def get_lineups(team_id_i):\n",
        "    try:\n",
        "        lineup = teamdashlineups.TeamDashLineups(\n",
        "            team_id=team_id_i,\n",
        "            season='2023-24',  # Using 2023-24 for more complete data\n",
        "            season_type_all_star='Regular Season',\n",
        "            group_quantity=5,  # 5-man lineups\n",
        "            per_mode_detailed='Totals'\n",
        "        )\n",
        "        df = lineup.get_data_frames()\n",
        "        all_lineups = df[1]  # This contains the lineup data\n",
        "        return all_lineups\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error getting lineups for team {team_id_i}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get lineups for all teams\n",
        "print(\"\\nüì• DOWNLOADING LINEUP DATA FOR ALL TEAMS...\")\n",
        "dataframes = []\n",
        "\n",
        "for i, team_name in enumerate(team_dict.keys()):\n",
        "    team_id_i = team_dict[team_name]\n",
        "    print(f\"   {i+1}/{len(team_dict)}: Getting {team_name}...\")\n",
        "\n",
        "    team_lineup = get_lineups(team_id_i)\n",
        "    if team_lineup is not None and not team_lineup.empty:\n",
        "        team_lineup['team'] = team_name\n",
        "        team_lineup['team_id'] = team_id_i\n",
        "        dataframes.append(team_lineup)\n",
        "\n",
        "    # Add small delay to avoid overwhelming API\n",
        "    import time\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Combine all team lineups\n",
        "if dataframes:\n",
        "    league_lineup = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    # Process the lineup data\n",
        "    league_lineup['players_list'] = league_lineup['GROUP_NAME'].str.split(' - ')\n",
        "\n",
        "    print(f\"\\n‚úÖ SUCCESS: Downloaded {len(league_lineup)} lineup combinations!\")\n",
        "    print(f\"üìä Dataset shape: {league_lineup.shape}\")\n",
        "\n",
        "    # Save the data\n",
        "    league_lineup.to_csv('nba_lineups_2024_api.csv', index=False)\n",
        "    print(\"üíæ Saved as 'nba_lineups_2024_api.csv'\")\n",
        "\n",
        "    # Show sample\n",
        "    print(\"\\nüîç SAMPLE OF REAL NBA LINEUP DATA:\")\n",
        "    display(league_lineup[['GROUP_NAME', 'team', 'MIN', 'PLUS_MINUS', 'FG_PCT', 'FG3_PCT']].head(3))\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No lineup data could be downloaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1qqh8cL-2qqX",
        "outputId": "65105ef5-9ee0-4871-e7dc-c978e5c6a678"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ GETTING REAL NBA LINEUP DATA FROM OFFICIAL NBA API...\n",
            "Requirement already satisfied: nba_api in /usr/local/lib/python3.12/dist-packages (1.10.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->nba_api) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nba_api) (1.17.0)\n",
            "‚úÖ Found 30 NBA teams\n",
            "\n",
            "üì• DOWNLOADING LINEUP DATA FOR ALL TEAMS...\n",
            "   1/30: Getting Atlanta Hawks...\n",
            "   2/30: Getting Boston Celtics...\n",
            "   3/30: Getting Cleveland Cavaliers...\n",
            "   4/30: Getting New Orleans Pelicans...\n",
            "   5/30: Getting Chicago Bulls...\n",
            "   6/30: Getting Dallas Mavericks...\n",
            "   7/30: Getting Denver Nuggets...\n",
            "   8/30: Getting Golden State Warriors...\n",
            "   9/30: Getting Houston Rockets...\n",
            "   10/30: Getting Los Angeles Clippers...\n",
            "   11/30: Getting Los Angeles Lakers...\n",
            "   12/30: Getting Miami Heat...\n",
            "   13/30: Getting Milwaukee Bucks...\n",
            "   14/30: Getting Minnesota Timberwolves...\n",
            "   15/30: Getting Brooklyn Nets...\n",
            "   16/30: Getting New York Knicks...\n",
            "   17/30: Getting Orlando Magic...\n",
            "   18/30: Getting Indiana Pacers...\n",
            "   19/30: Getting Philadelphia 76ers...\n",
            "   20/30: Getting Phoenix Suns...\n",
            "   21/30: Getting Portland Trail Blazers...\n",
            "   22/30: Getting Sacramento Kings...\n",
            "   23/30: Getting San Antonio Spurs...\n",
            "   24/30: Getting Oklahoma City Thunder...\n",
            "   25/30: Getting Toronto Raptors...\n",
            "   26/30: Getting Utah Jazz...\n",
            "   27/30: Getting Memphis Grizzlies...\n",
            "   28/30: Getting Washington Wizards...\n",
            "   29/30: Getting Detroit Pistons...\n",
            "   30/30: Getting Charlotte Hornets...\n",
            "\n",
            "‚úÖ SUCCESS: Downloaded 7500 lineup combinations!\n",
            "üìä Dataset shape: (7500, 59)\n",
            "üíæ Saved as 'nba_lineups_2024_api.csv'\n",
            "\n",
            "üîç SAMPLE OF REAL NBA LINEUP DATA:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          GROUP_NAME           team  \\\n",
              "0  C. Capela - D. Murray - T. Young - S. Bey - J....  Atlanta Hawks   \n",
              "1  C. Capela - D. Murray - T. Young - D. Hunter -...  Atlanta Hawks   \n",
              "2  C. Capela - D. Murray - T. Young - D. Hunter -...  Atlanta Hawks   \n",
              "\n",
              "          MIN  PLUS_MINUS  FG_PCT  FG3_PCT  \n",
              "0  288.680000       -88.0   0.446    0.312  \n",
              "1  176.911667         8.0   0.468    0.384  \n",
              "2  171.505000       -26.0   0.464    0.367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c936390c-4e41-4935-89a3-2c7501f20da3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GROUP_NAME</th>\n",
              "      <th>team</th>\n",
              "      <th>MIN</th>\n",
              "      <th>PLUS_MINUS</th>\n",
              "      <th>FG_PCT</th>\n",
              "      <th>FG3_PCT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C. Capela - D. Murray - T. Young - S. Bey - J....</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>288.680000</td>\n",
              "      <td>-88.0</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C. Capela - D. Murray - T. Young - D. Hunter -...</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>176.911667</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C. Capela - D. Murray - T. Young - D. Hunter -...</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>171.505000</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c936390c-4e41-4935-89a3-2c7501f20da3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c936390c-4e41-4935-89a3-2c7501f20da3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c936390c-4e41-4935-89a3-2c7501f20da3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea3e56b6-114a-4b55-882a-840a8eda8434\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea3e56b6-114a-4b55-882a-840a8eda8434')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea3e56b6-114a-4b55-882a-840a8eda8434 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\u274c No lineup data could be downloaded\\\")\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"GROUP_NAME\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C. Capela - D. Murray - T. Young - S. Bey - J. Johnson\",\n          \"C. Capela - D. Murray - T. Young - D. Hunter - S. Bey\",\n          \"C. Capela - D. Murray - T. Young - D. Hunter - J. Johnson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Atlanta Hawks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66.14551248906683,\n        \"min\": 171.505,\n        \"max\": 288.68,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          288.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PLUS_MINUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48.67579823005816,\n        \"min\": -88.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -88.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FG_PCT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01171893055416464,\n        \"min\": 0.446,\n        \"max\": 0.468,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FG3_PCT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03763420430052074,\n        \"min\": 0.312,\n        \"max\": 0.384,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1.2: Analyze the API Data Structure"
      ],
      "metadata": {
        "id": "rofuD_Ck5wM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üî¨ ANALYZING NBA API DATA STRUCTURE...\")\n",
        "\n",
        "try:\n",
        "    lineup_data = pd.read_csv('nba_lineups_2024_api.csv')\n",
        "\n",
        "    print(\"üìã COLUMNS AVAILABLE:\")\n",
        "    for col in lineup_data.columns:\n",
        "        print(f\"   - {col}\")\n",
        "\n",
        "    print(\"\\nüéØ VARIABLES FOR OUR BAYESIAN NETWORK:\")\n",
        "\n",
        "    # Check for critical variables\n",
        "    critical_vars = {\n",
        "        'Efficiency (Target)': ['PLUS_MINUS', 'PTS'],\n",
        "        'Shooting': ['FG_PCT', 'FG3_PCT', 'EFG_PCT'],\n",
        "        'Playmaking': ['AST', 'AST_PCT'],\n",
        "        'Rebounding': ['OREB', 'DREB', 'REB'],\n",
        "        'Turnovers': ['TOV', 'TOV_PCT']\n",
        "    }\n",
        "\n",
        "    available_cols = lineup_data.columns.tolist()\n",
        "\n",
        "    for category, possible_vars in critical_vars.items():\n",
        "        found = [var for var in possible_vars if var in available_cols]\n",
        "        if found:\n",
        "            print(f\"   ‚úÖ {category}: {found}\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå {category}: Not found\")\n",
        "\n",
        "    print(f\"\\nüìä Dataset info: {lineup_data.shape}\")\n",
        "    print(f\"üë• Unique lineups: {lineup_data['GROUP_NAME'].nunique()}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error analyzing data: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTmSlmAM4Yci",
        "outputId": "aa57bad1-de06-4c9e-d274-3a5574a1c68f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî¨ ANALYZING NBA API DATA STRUCTURE...\n",
            "üìã COLUMNS AVAILABLE:\n",
            "   - GROUP_SET\n",
            "   - GROUP_ID\n",
            "   - GROUP_NAME\n",
            "   - GP\n",
            "   - W\n",
            "   - L\n",
            "   - W_PCT\n",
            "   - MIN\n",
            "   - FGM\n",
            "   - FGA\n",
            "   - FG_PCT\n",
            "   - FG3M\n",
            "   - FG3A\n",
            "   - FG3_PCT\n",
            "   - FTM\n",
            "   - FTA\n",
            "   - FT_PCT\n",
            "   - OREB\n",
            "   - DREB\n",
            "   - REB\n",
            "   - AST\n",
            "   - TOV\n",
            "   - STL\n",
            "   - BLK\n",
            "   - BLKA\n",
            "   - PF\n",
            "   - PFD\n",
            "   - PTS\n",
            "   - PLUS_MINUS\n",
            "   - GP_RANK\n",
            "   - W_RANK\n",
            "   - L_RANK\n",
            "   - W_PCT_RANK\n",
            "   - MIN_RANK\n",
            "   - FGM_RANK\n",
            "   - FGA_RANK\n",
            "   - FG_PCT_RANK\n",
            "   - FG3M_RANK\n",
            "   - FG3A_RANK\n",
            "   - FG3_PCT_RANK\n",
            "   - FTM_RANK\n",
            "   - FTA_RANK\n",
            "   - FT_PCT_RANK\n",
            "   - OREB_RANK\n",
            "   - DREB_RANK\n",
            "   - REB_RANK\n",
            "   - AST_RANK\n",
            "   - TOV_RANK\n",
            "   - STL_RANK\n",
            "   - BLK_RANK\n",
            "   - BLKA_RANK\n",
            "   - PF_RANK\n",
            "   - PFD_RANK\n",
            "   - PTS_RANK\n",
            "   - PLUS_MINUS_RANK\n",
            "   - SUM_TIME_PLAYED\n",
            "   - team\n",
            "   - team_id\n",
            "   - players_list\n",
            "\n",
            "üéØ VARIABLES FOR OUR BAYESIAN NETWORK:\n",
            "   ‚úÖ Efficiency (Target): ['PLUS_MINUS', 'PTS']\n",
            "   ‚úÖ Shooting: ['FG_PCT', 'FG3_PCT']\n",
            "   ‚úÖ Playmaking: ['AST']\n",
            "   ‚úÖ Rebounding: ['OREB', 'DREB', 'REB']\n",
            "   ‚úÖ Turnovers: ['TOV']\n",
            "\n",
            "üìä Dataset info: (7500, 59)\n",
            "üë• Unique lineups: 7485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 1.3: Integration with Kaggle Data"
      ],
      "metadata": {
        "id": "XAJTCj5c6LHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 1.3 FIXED: USE ONLY NBA API DATA ===\n",
        "print(\"=== PHASE 1.3: PROPER NBA API DATA INTEGRATION ===\")\n",
        "\n",
        "# Load the NBA API data we just downloaded\n",
        "print(\"üì• Loading NBA API lineup data...\")\n",
        "lineup_data = pd.read_csv('nba_lineups_2024_api.csv')\n",
        "\n",
        "print(f\"üìä Original NBA API data: {lineup_data.shape}\")\n",
        "\n",
        "# Select only the variables we need for our Bayesian network\n",
        "print(\"\\nüéØ SELECTING VARIABLES FOR BAYESIAN NETWORK:\")\n",
        "selected_vars = {\n",
        "    'Efficiency': 'PLUS_MINUS',  # Net rating as efficiency proxy\n",
        "    'Shooting_FG': 'FG_PCT',     # Field goal percentage\n",
        "    'Shooting_3PT': 'FG3_PCT',   # 3-point percentage\n",
        "    'Playmaking': 'AST',         # Assists\n",
        "    'Turnovers': 'TOV',          # Turnovers\n",
        "    'Offensive_Rebounding': 'OREB'  # Offensive rebounds\n",
        "}\n",
        "\n",
        "# Create our feature dataset\n",
        "print(\"üîß Creating feature dataset from NBA API data...\")\n",
        "feature_data = lineup_data[list(selected_vars.values())].copy()\n",
        "feature_data.columns = list(selected_vars.keys())\n",
        "\n",
        "print(f\"üìä Feature dataset shape: {feature_data.shape}\")\n",
        "\n",
        "# Remove any missing values\n",
        "feature_data = feature_data.dropna()\n",
        "print(f\"üìä After removing missing values: {feature_data.shape}\")\n",
        "\n",
        "# Check data quality\n",
        "print(\"\\nüîç DATA QUALITY CHECK:\")\n",
        "print(\"Basic statistics:\")\n",
        "print(feature_data.describe())\n",
        "\n",
        "# Check for reasonable ranges (basketball logic)\n",
        "print(\"\\nüèÄ BASKETBALL LOGIC VALIDATION:\")\n",
        "print(\"Ranges should make sense for NBA:\")\n",
        "for col in feature_data.columns:\n",
        "    min_val = feature_data[col].min()\n",
        "    max_val = feature_data[col].max()\n",
        "    print(f\"  {col}: {min_val:.2f} to {max_val:.2f}\")\n",
        "\n",
        "# Verify we have enough data for discretization\n",
        "print(f\"\\nüìà DATA SUFFICIENCY:\")\n",
        "print(f\"  Total samples: {len(feature_data)}\")\n",
        "print(f\"  Minimum required: ~1,000 (for 3^5=243 combinations)\")\n",
        "print(f\"  Status: {'‚úÖ SUFFICIENT' if len(feature_data) >= 1000 else '‚ùå INSUFFICIENT'}\")\n",
        "\n",
        "if len(feature_data) >= 1000:\n",
        "    # Save the integrated data for Phase 2\n",
        "    feature_data.to_csv('nba_api_integrated_data.csv', index=False)\n",
        "    print(\"üíæ Saved integrated data as 'nba_api_integrated_data.csv'\")\n",
        "\n",
        "    print(\"\\n‚úÖ PHASE 1.3 COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"üéØ Using ONLY NBA API data for consistency\")\n",
        "    print(\"üöÄ Ready for Phase 2: Data Preprocessing\")\n",
        "else:\n",
        "    print(\"\\n‚ùå INSUFFICIENT DATA - Need to collect more NBA API data\")\n",
        "    print(\"   Consider multiple seasons or different API endpoints\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCNxl6HW6C69",
        "outputId": "d1073561-fb2f-4bdb-e535-a2d39ee43258"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 1.3: PROPER NBA API DATA INTEGRATION ===\n",
            "üì• Loading NBA API lineup data...\n",
            "üìä Original NBA API data: (7500, 59)\n",
            "\n",
            "üéØ SELECTING VARIABLES FOR BAYESIAN NETWORK:\n",
            "üîß Creating feature dataset from NBA API data...\n",
            "üìä Feature dataset shape: (7500, 6)\n",
            "üìä After removing missing values: (7500, 6)\n",
            "\n",
            "üîç DATA QUALITY CHECK:\n",
            "Basic statistics:\n",
            "        Efficiency  Shooting_FG  Shooting_3PT   Playmaking    Turnovers  \\\n",
            "count  7500.000000  7500.000000   7500.000000  7500.000000  7500.000000   \n",
            "mean      0.555867     0.473603      0.354854     7.921333     3.910133   \n",
            "std      11.382578     0.151966      0.248258    21.286298     9.458745   \n",
            "min     -88.000000     0.000000      0.000000     0.000000     0.000000   \n",
            "25%      -5.000000     0.387000      0.200000     2.000000     1.000000   \n",
            "50%       0.000000     0.476000      0.333000     4.000000     2.000000   \n",
            "75%       5.000000     0.563000      0.500000     7.000000     4.000000   \n",
            "max     282.000000     1.000000      1.000000   615.000000   228.000000   \n",
            "\n",
            "       Offensive_Rebounding  \n",
            "count           7500.000000  \n",
            "mean               3.066533  \n",
            "std                7.285684  \n",
            "min                0.000000  \n",
            "25%                1.000000  \n",
            "50%                2.000000  \n",
            "75%                3.000000  \n",
            "max              216.000000  \n",
            "\n",
            "üèÄ BASKETBALL LOGIC VALIDATION:\n",
            "Ranges should make sense for NBA:\n",
            "  Efficiency: -88.00 to 282.00\n",
            "  Shooting_FG: 0.00 to 1.00\n",
            "  Shooting_3PT: 0.00 to 1.00\n",
            "  Playmaking: 0.00 to 615.00\n",
            "  Turnovers: 0.00 to 228.00\n",
            "  Offensive_Rebounding: 0.00 to 216.00\n",
            "\n",
            "üìà DATA SUFFICIENCY:\n",
            "  Total samples: 7500\n",
            "  Minimum required: ~1,000 (for 3^5=243 combinations)\n",
            "  Status: ‚úÖ SUFFICIENT\n",
            "üíæ Saved integrated data as 'nba_api_integrated_data.csv'\n",
            "\n",
            "‚úÖ PHASE 1.3 COMPLETED SUCCESSFULLY!\n",
            "üéØ Using ONLY NBA API data for consistency\n",
            "üöÄ Ready for Phase 2: Data Preprocessing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: Data Preprocessing & Discretization\n"
      ],
      "metadata": {
        "id": "4nllLMTF7tti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.1: Data Cleaning & Filtering"
      ],
      "metadata": {
        "id": "Vk1PULRsC_J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 2.1 UPDATED: CLEAN NBA API DATA ===\n",
        "print(\"=== PHASE 2.1: CLEANING NBA API DATA ===\")\n",
        "\n",
        "# Load the integrated NBA API data\n",
        "print(\"üì• Loading integrated NBA API data...\")\n",
        "nba_api_data = pd.read_csv('nba_api_integrated_data.csv')\n",
        "\n",
        "print(f\"üìä Dataset shape: {nba_api_data.shape}\")\n",
        "print(f\"üéØ Columns: {list(nba_api_data.columns)}\")\n",
        "\n",
        "# The data is already clean (no missing values), but let's verify\n",
        "print(\"\\nüîç DATA CLEANLINESS CHECK:\")\n",
        "print(f\"Missing values: {nba_api_data.isnull().sum().sum()}\")  # Should be 0\n",
        "print(f\"Duplicate rows: {nba_api_data.duplicated().sum()}\")    # Should be minimal\n",
        "\n",
        "# Check for extreme outliers that might skew discretization\n",
        "print(\"\\nüìä OUTLIER DETECTION:\")\n",
        "for col in nba_api_data.columns:\n",
        "    Q1 = nba_api_data[col].quantile(0.25)\n",
        "    Q3 = nba_api_data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = nba_api_data[(nba_api_data[col] < lower_bound) | (nba_api_data[col] > upper_bound)]\n",
        "    print(f\"  {col}: {len(outliers)} outliers ({len(outliers)/len(nba_api_data):.1%})\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 2.1 COMPLETED!\")\n",
        "print(\"üöÄ Ready for Phase 2.2: Feature Selection & Engineering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJpoQpP_DJZk",
        "outputId": "7a8d2940-0557-4966-8528-a0c60c439c4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 2.1: CLEANING NBA API DATA ===\n",
            "üì• Loading integrated NBA API data...\n",
            "üìä Dataset shape: (7500, 6)\n",
            "üéØ Columns: ['Efficiency', 'Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Turnovers', 'Offensive_Rebounding']\n",
            "\n",
            "üîç DATA CLEANLINESS CHECK:\n",
            "Missing values: 0\n",
            "Duplicate rows: 162\n",
            "\n",
            "üìä OUTLIER DETECTION:\n",
            "  Efficiency: 324 outliers (4.3%)\n",
            "  Shooting_FG: 234 outliers (3.1%)\n",
            "  Shooting_3PT: 343 outliers (4.6%)\n",
            "  Playmaking: 777 outliers (10.4%)\n",
            "  Turnovers: 628 outliers (8.4%)\n",
            "  Offensive_Rebounding: 729 outliers (9.7%)\n",
            "\n",
            "‚úÖ PHASE 2.1 COMPLETED!\n",
            "üöÄ Ready for Phase 2.2: Feature Selection & Engineering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.2: Data Preprocessing & Engineering"
      ],
      "metadata": {
        "id": "g0tg2l2IDcF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 2.2 FIXED: PROPER RATE STATISTICS ===\n",
        "print(\"=== PHASE 2.2 FIXED: PROPER RATE STATISTICS ===\")\n",
        "\n",
        "# We need the original lineup data with MINUTES to convert to rates\n",
        "print(\"üì• Loading full NBA lineup data with minutes...\")\n",
        "lineup_data = pd.read_csv('nba_lineups_2024_api.csv')\n",
        "\n",
        "print(\"üîß Converting totals to per-minute rates...\")\n",
        "\n",
        "# Calculate rates per 48 minutes (standard NBA rate)\n",
        "def calculate_rates(data):\n",
        "    rates_data = data.copy()\n",
        "\n",
        "    # Efficiency stays as PLUS_MINUS (already a rate)\n",
        "    rates_data['Efficiency'] = data['PLUS_MINUS']\n",
        "\n",
        "    # Convert totals to per-48-minute rates\n",
        "    minutes = data['MIN']\n",
        "\n",
        "    # Shooting percentages stay the same (already rates)\n",
        "    rates_data['Shooting_FG'] = data['FG_PCT']\n",
        "    rates_data['Shooting_3PT'] = data['FG3_PCT']\n",
        "\n",
        "    # Playmaking: Assists per 48 minutes\n",
        "    rates_data['Playmaking'] = (data['AST'] / minutes) * 48\n",
        "\n",
        "    # Turnovers: Turnovers per 48 minutes (INVERTED - lower is better)\n",
        "    rates_data['Turnovers'] = (data['TOV'] / minutes) * 48\n",
        "\n",
        "    # Offensive Rebounding: Offensive rebounds per 48 minutes\n",
        "    rates_data['Offensive_Rebounding'] = (data['OREB'] / minutes) * 48\n",
        "\n",
        "    return rates_data\n",
        "\n",
        "# Create rate-based features\n",
        "rates_data = calculate_rates(lineup_data)\n",
        "\n",
        "# Select only our 6 key variables\n",
        "rates_data = rates_data[['Efficiency', 'Shooting_FG', 'Shooting_3PT',\n",
        "                        'Playmaking', 'Turnovers', 'Offensive_Rebounding']]\n",
        "\n",
        "# Remove any infinite/NaN values from division\n",
        "rates_data = rates_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "print(f\"üìä Rate-based dataset shape: {rates_data.shape}\")\n",
        "\n",
        "# Check new correlations\n",
        "print(\"\\nüìä FIXED CORRELATIONS WITH EFFICIENCY:\")\n",
        "corr_matrix = rates_data.corr()\n",
        "efficiency_correlations = corr_matrix['Efficiency'].sort_values(ascending=False)\n",
        "\n",
        "for feature, corr in efficiency_correlations.items():\n",
        "    if feature != 'Efficiency':\n",
        "        print(f\"   {feature}: {corr:.3f}\")\n",
        "\n",
        "# Verify basketball logic is now correct\n",
        "positive_expected = ['Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Offensive_Rebounding']\n",
        "negative_expected = ['Turnovers']\n",
        "\n",
        "actual_positive = [f for f in efficiency_correlations.index\n",
        "                  if f != 'Efficiency' and efficiency_correlations[f] > 0]\n",
        "actual_negative = [f for f in efficiency_correlations.index\n",
        "                  if f != 'Efficiency' and efficiency_correlations[f] < 0]\n",
        "\n",
        "print(f\"\\n‚úÖ Expected Positive: {positive_expected}\")\n",
        "print(f\"‚úÖ Expected Negative: {negative_expected}\")\n",
        "print(f\"üìä Actual Positive: {actual_positive}\")\n",
        "print(f\"üìä Actual Negative: {actual_negative}\")\n",
        "\n",
        "# Basketball logic validation\n",
        "if 'Turnovers' in actual_negative:\n",
        "    print(\"üéØ BASKETBALL LOGIC: Turnovers now negatively correlate with efficiency ‚úì\")\n",
        "else:\n",
        "    print(\"‚ùå BASKETBALL LOGIC STILL BROKEN - Need further investigation\")\n",
        "\n",
        "# Save the corrected data\n",
        "rates_data.to_csv('nba_api_corrected_rates.csv', index=False)\n",
        "print(\"\\nüíæ Saved corrected rate-based data as 'nba_api_corrected_rates.csv'\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 2.2 FIXED COMPLETED!\")\n",
        "print(\"üöÄ Ready for Phase 2.3 with proper basketball logic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hOKZBCpDOqe",
        "outputId": "7096bd62-a19c-4259-deb7-c734e3845ed0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 2.2 FIXED: PROPER RATE STATISTICS ===\n",
            "üì• Loading full NBA lineup data with minutes...\n",
            "üîß Converting totals to per-minute rates...\n",
            "üìä Rate-based dataset shape: (7500, 6)\n",
            "\n",
            "üìä FIXED CORRELATIONS WITH EFFICIENCY:\n",
            "   Shooting_FG: 0.329\n",
            "   Playmaking: 0.274\n",
            "   Shooting_3PT: 0.223\n",
            "   Offensive_Rebounding: 0.022\n",
            "   Turnovers: -0.141\n",
            "\n",
            "‚úÖ Expected Positive: ['Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Offensive_Rebounding']\n",
            "‚úÖ Expected Negative: ['Turnovers']\n",
            "üìä Actual Positive: ['Shooting_FG', 'Playmaking', 'Shooting_3PT', 'Offensive_Rebounding']\n",
            "üìä Actual Negative: ['Turnovers']\n",
            "üéØ BASKETBALL LOGIC: Turnovers now negatively correlate with efficiency ‚úì\n",
            "\n",
            "üíæ Saved corrected rate-based data as 'nba_api_corrected_rates.csv'\n",
            "\n",
            "‚úÖ PHASE 2.2 FIXED COMPLETED!\n",
            "üöÄ Ready for Phase 2.3 with proper basketball logic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.3: Discretization"
      ],
      "metadata": {
        "id": "V68gXp26D0RZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 2.3: SMART DISCRETIZATION ===\n",
        "print(\"=== PHASE 2.3: SMART DISCRETIZATION ===\")\n",
        "\n",
        "# Load the corrected rate-based data\n",
        "print(\"üì• Loading corrected rate-based data...\")\n",
        "rates_data = pd.read_csv('nba_api_corrected_rates.csv')\n",
        "\n",
        "print(f\"üìä Dataset shape: {rates_data.shape}\")\n",
        "print(\"üéØ Variables to discretize: Efficiency, Shooting_FG, Shooting_3PT, Playmaking, Turnovers, Offensive_Rebounding\")\n",
        "\n",
        "# Define basketball-informed discretization thresholds\n",
        "print(\"\\nüèÄ SETTING BASKETBALL-INFORMED THRESHOLDS:\")\n",
        "\n",
        "discretization_rules = {\n",
        "    'Efficiency': {\n",
        "        'description': 'Plus/Minus per game',\n",
        "        'Low': ('Below -5', 'Negative impact'),\n",
        "        'Medium': ('-5 to +5', 'Neutral impact'),\n",
        "        'High': ('Above +5', 'Positive impact')\n",
        "    },\n",
        "    'Shooting_FG': {\n",
        "        'description': 'Field Goal Percentage',\n",
        "        'Low': ('Below 45%', 'Poor shooting'),\n",
        "        'Medium': ('45% to 50%', 'Average shooting'),\n",
        "        'High': ('Above 50%', 'Elite shooting')\n",
        "    },\n",
        "    'Shooting_3PT': {\n",
        "        'description': '3-Point Percentage',\n",
        "        'Low': ('Below 35%', 'Poor 3PT'),\n",
        "        'Medium': ('35% to 40%', 'Average 3PT'),\n",
        "        'High': ('Above 40%', 'Elite 3PT')\n",
        "    },\n",
        "    'Playmaking': {\n",
        "        'description': 'Assists per 48 minutes',\n",
        "        'Low': ('Below 15', 'Low playmaking'),\n",
        "        'Medium': ('15 to 25', 'Average playmaking'),\n",
        "        'High': ('Above 25', 'High playmaking')\n",
        "    },\n",
        "    'Turnovers': {\n",
        "        'description': 'Turnovers per 48 minutes',\n",
        "        'Low': ('Below 10', 'Good ball control'),  # Lower turnovers = better\n",
        "        'Medium': ('10 to 15', 'Average ball control'),\n",
        "        'High': ('Above 15', 'Poor ball control')  # Higher turnovers = worse\n",
        "    },\n",
        "    'Offensive_Rebounding': {\n",
        "        'description': 'Offensive Rebounds per 48 minutes',\n",
        "        'Low': ('Below 8', 'Poor offensive rebounding'),\n",
        "        'Medium': ('8 to 12', 'Average offensive rebounding'),\n",
        "        'High': ('Above 12', 'Elite offensive rebounding')\n",
        "    }\n",
        "}\n",
        "\n",
        "# Apply discretization\n",
        "print(\"\\nüîß APPLYING DISCRETIZATION...\")\n",
        "final_discretized_data = rates_data.copy()\n",
        "\n",
        "for column in final_discretized_data.columns:\n",
        "    if column == 'Efficiency':\n",
        "        bins = [-float('inf'), -5, 5, float('inf')]\n",
        "        labels = ['Low', 'Medium', 'High']\n",
        "    elif column == 'Shooting_FG':\n",
        "        bins = [-float('inf'), 0.45, 0.50, float('inf')]\n",
        "        labels = ['Low', 'Medium', 'High']\n",
        "    elif column == 'Shooting_3PT':\n",
        "        bins = [-float('inf'), 0.35, 0.40, float('inf')]\n",
        "        labels = ['Low', 'Medium', 'High']\n",
        "    elif column == 'Playmaking':\n",
        "        bins = [-float('inf'), 15, 25, float('inf')]\n",
        "        labels = ['Low', 'Medium', 'High']\n",
        "    elif column == 'Turnovers':\n",
        "        bins = [-float('inf'), 10, 15, float('inf')]\n",
        "        labels = ['Low', 'Medium', 'High']  # Lower turnovers = \"Low\" category (good)\n",
        "    elif column == 'Offensive_Rebounding':\n",
        "        bins = [-float('inf'), 8, 12, float('inf')]\n",
        "        labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "    final_discretized_data[column] = pd.cut(final_discretized_data[column], bins=bins, labels=labels)\n",
        "\n",
        "print(\"‚úÖ DISCRETIZATION COMPLETED!\")\n",
        "\n",
        "# Check the distribution of discretized variables\n",
        "print(\"\\nüìä DISCRETIZED DISTRIBUTIONS:\")\n",
        "for column in final_discretized_data.columns:\n",
        "    dist = final_discretized_data[column].value_counts(normalize=True).sort_index()\n",
        "    print(f\"{column}:\")\n",
        "    for state in ['Low', 'Medium', 'High']:\n",
        "        count = final_discretized_data[column].value_counts().get(state, 0)\n",
        "        percentage = dist.get(state, 0) * 100\n",
        "        print(f\"  {state}: {count} samples ({percentage:.1f}%)\")\n",
        "\n",
        "# Verify we have enough samples in each category\n",
        "print(\"\\nüîç SAMPLE SUFFICIENCY CHECK:\")\n",
        "min_samples = 100  # Minimum samples per category for reliable learning\n",
        "for column in final_discretized_data.columns:\n",
        "    for state in ['Low', 'Medium', 'High']:\n",
        "        count = (final_discretized_data[column] == state).sum()\n",
        "        if count < min_samples:\n",
        "            print(f\"‚ö†Ô∏è  {column}-{state}: Only {count} samples\")\n",
        "        else:\n",
        "            print(f\"‚úÖ {column}-{state}: {count} samples\")\n",
        "\n",
        "# Save the final discretized data\n",
        "final_discretized_data.to_csv('final_discretized_nba_data.csv', index=False)\n",
        "print(\"\\nüíæ Saved final discretized data as 'final_discretized_nba_data.csv'\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 2.3 COMPLETED!\")\n",
        "print(\"üöÄ Ready for Phase 2.4: Save Processed Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15d8FAfrENif",
        "outputId": "b6d5cff2-fbd0-4d24-d611-b16e3935f62e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 2.3: SMART DISCRETIZATION ===\n",
            "üì• Loading corrected rate-based data...\n",
            "üìä Dataset shape: (7500, 6)\n",
            "üéØ Variables to discretize: Efficiency, Shooting_FG, Shooting_3PT, Playmaking, Turnovers, Offensive_Rebounding\n",
            "\n",
            "üèÄ SETTING BASKETBALL-INFORMED THRESHOLDS:\n",
            "\n",
            "üîß APPLYING DISCRETIZATION...\n",
            "‚úÖ DISCRETIZATION COMPLETED!\n",
            "\n",
            "üìä DISCRETIZED DISTRIBUTIONS:\n",
            "Efficiency:\n",
            "  Low: 1906 samples (25.4%)\n",
            "  Medium: 3912 samples (52.2%)\n",
            "  High: 1682 samples (22.4%)\n",
            "Shooting_FG:\n",
            "  Low: 3229 samples (43.1%)\n",
            "  Medium: 1545 samples (20.6%)\n",
            "  High: 2726 samples (36.3%)\n",
            "Shooting_3PT:\n",
            "  Low: 3889 samples (51.9%)\n",
            "  Medium: 750 samples (10.0%)\n",
            "  High: 2861 samples (38.1%)\n",
            "Playmaking:\n",
            "  Low: 1385 samples (18.5%)\n",
            "  Medium: 2185 samples (29.1%)\n",
            "  High: 3930 samples (52.4%)\n",
            "Turnovers:\n",
            "  Low: 2707 samples (36.1%)\n",
            "  Medium: 1935 samples (25.8%)\n",
            "  High: 2858 samples (38.1%)\n",
            "Offensive_Rebounding:\n",
            "  Low: 3118 samples (41.6%)\n",
            "  Medium: 1565 samples (20.9%)\n",
            "  High: 2817 samples (37.6%)\n",
            "\n",
            "üîç SAMPLE SUFFICIENCY CHECK:\n",
            "‚úÖ Efficiency-Low: 1906 samples\n",
            "‚úÖ Efficiency-Medium: 3912 samples\n",
            "‚úÖ Efficiency-High: 1682 samples\n",
            "‚úÖ Shooting_FG-Low: 3229 samples\n",
            "‚úÖ Shooting_FG-Medium: 1545 samples\n",
            "‚úÖ Shooting_FG-High: 2726 samples\n",
            "‚úÖ Shooting_3PT-Low: 3889 samples\n",
            "‚úÖ Shooting_3PT-Medium: 750 samples\n",
            "‚úÖ Shooting_3PT-High: 2861 samples\n",
            "‚úÖ Playmaking-Low: 1385 samples\n",
            "‚úÖ Playmaking-Medium: 2185 samples\n",
            "‚úÖ Playmaking-High: 3930 samples\n",
            "‚úÖ Turnovers-Low: 2707 samples\n",
            "‚úÖ Turnovers-Medium: 1935 samples\n",
            "‚úÖ Turnovers-High: 2858 samples\n",
            "‚úÖ Offensive_Rebounding-Low: 3118 samples\n",
            "‚úÖ Offensive_Rebounding-Medium: 1565 samples\n",
            "‚úÖ Offensive_Rebounding-High: 2817 samples\n",
            "\n",
            "üíæ Saved final discretized data as 'final_discretized_nba_data.csv'\n",
            "\n",
            "‚úÖ PHASE 2.3 COMPLETED!\n",
            "üöÄ Ready for Phase 2.4: Save Processed Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 2.4: Save Processed Data & Phase Completion"
      ],
      "metadata": {
        "id": "vnVHUPO7HFP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 2.4: SAVE PROCESSED DATA ===\n",
        "print(\"=== PHASE 2.4: SAVE PROCESSED DATA ===\")\n",
        "\n",
        "# Verify the final dataset\n",
        "print(\"üîç FINAL DATASET VERIFICATION:\")\n",
        "print(f\"üìä Shape: {final_discretized_data.shape}\")\n",
        "print(f\"üéØ Columns: {list(final_discretized_data.columns)}\")\n",
        "print(f\"üìà Total samples: {len(final_discretized_data)}\")\n",
        "\n",
        "# Check data types and ensure proper categorical encoding\n",
        "print(\"\\nüîß DATA TYPE OPTIMIZATION:\")\n",
        "for col in final_discretized_data.columns:\n",
        "    unique_vals = final_discretized_data[col].unique()\n",
        "    print(f\"  {col}: {list(unique_vals)} - {final_discretized_data[col].dtype}\")\n",
        "\n",
        "# Convert to categorical with logical order for Bayesian network\n",
        "print(\"\\nüéØ OPTIMIZING FOR BAYESIAN NETWORK:\")\n",
        "final_processed_data = final_discretized_data.copy()\n",
        "\n",
        "# Ensure consistent categorical ordering\n",
        "for col in final_processed_data.columns:\n",
        "    final_processed_data[col] = pd.Categorical(\n",
        "        final_processed_data[col],\n",
        "        categories=['Low', 'Medium', 'High'],\n",
        "        ordered=True\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ All variables encoded as ordered categoricals\")\n",
        "\n",
        "# Final save\n",
        "final_processed_data.to_csv('nba_lineup_efficiency_final_data.csv', index=False)\n",
        "print(\"üíæ Saved as 'nba_lineup_efficiency_final_data.csv'\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nüìã FINAL DATASET SUMMARY:\")\n",
        "print(f\"‚úÖ Samples: {len(final_processed_data):,}\")\n",
        "print(f\"‚úÖ Features: {len(final_processed_data.columns)}\")\n",
        "print(f\"‚úÖ Data types: All categorical (Low/Medium/High)\")\n",
        "print(f\"‚úÖ Basketball logic: Preserved through discretization\")\n",
        "print(f\"‚úÖ Ready for Bayesian network training\")\n",
        "\n",
        "print(\"\\nüéâ PHASE 2 COMPLETED SUCCESSFULLY!\")\n",
        "print(\"üöÄ READY FOR PHASE 3: BAYESIAN NETWORK STRUCTURE & LEARNING\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm-B1fFyGZ4V",
        "outputId": "70326755-9cc5-4a33-db55-28885b27c02a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 2.4: SAVE PROCESSED DATA ===\n",
            "üîç FINAL DATASET VERIFICATION:\n",
            "üìä Shape: (7500, 6)\n",
            "üéØ Columns: ['Efficiency', 'Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Turnovers', 'Offensive_Rebounding']\n",
            "üìà Total samples: 7500\n",
            "\n",
            "üîß DATA TYPE OPTIMIZATION:\n",
            "  Efficiency: ['Low', 'High', 'Medium'] - category\n",
            "  Shooting_FG: ['Low', 'Medium', 'High'] - category\n",
            "  Shooting_3PT: ['Low', 'Medium', 'High'] - category\n",
            "  Playmaking: ['High', 'Medium', 'Low'] - category\n",
            "  Turnovers: ['High', 'Medium', 'Low'] - category\n",
            "  Offensive_Rebounding: ['High', 'Medium', 'Low'] - category\n",
            "\n",
            "üéØ OPTIMIZING FOR BAYESIAN NETWORK:\n",
            "‚úÖ All variables encoded as ordered categoricals\n",
            "üíæ Saved as 'nba_lineup_efficiency_final_data.csv'\n",
            "\n",
            "üìã FINAL DATASET SUMMARY:\n",
            "‚úÖ Samples: 7,500\n",
            "‚úÖ Features: 6\n",
            "‚úÖ Data types: All categorical (Low/Medium/High)\n",
            "‚úÖ Basketball logic: Preserved through discretization\n",
            "‚úÖ Ready for Bayesian network training\n",
            "\n",
            "üéâ PHASE 2 COMPLETED SUCCESSFULLY!\n",
            "üöÄ READY FOR PHASE 3: BAYESIAN NETWORK STRUCTURE & LEARNING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 3: Bayesian Network Structure & Learning"
      ],
      "metadata": {
        "id": "7zPW9SS-HP41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3.1: Design the DAG Structure"
      ],
      "metadata": {
        "id": "qnPBeD5EHVOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 3.1: HIERARCHICAL NETWORK STRUCTURE (RESTART) ===\n",
        "print(\"=== PHASE 3.1: HIERARCHICAL NETWORK STRUCTURE ===\")\n",
        "\n",
        "# Load the clean, processed data\n",
        "print(\"üì• Loading final processed data...\")\n",
        "final_data = pd.read_csv('nba_lineup_efficiency_final_data.csv')\n",
        "\n",
        "print(f\"üìä Dataset shape: {final_data.shape}\")\n",
        "print(f\"üéØ Columns: {list(final_data.columns)}\")\n",
        "\n",
        "# Verify data types are correct for Bayesian network\n",
        "print(\"\\nüîç DATA TYPE VERIFICATION:\")\n",
        "for col in final_data.columns:\n",
        "    print(f\"  {col}: {final_data[col].dtype} - {list(final_data[col].unique())}\")\n",
        "\n",
        "# Define the same hierarchical structure\n",
        "print(\"\\nüîó DESIGNING HIERARCHICAL STRUCTURE...\")\n",
        "print(\"üèÄ BASKETBALL LOGIC:\")\n",
        "print(\"  Level 0: Shooting_FG, Shooting_3PT, Playmaking, Turnovers, Offensive_Rebounding\")\n",
        "print(\"  Level 1: Shooting_Quality ‚Üê [FG + 3PT], Ball_Control ‚Üê [Playmaking - Turnovers]\")\n",
        "print(\"  Level 2: Efficiency ‚Üê [Shooting_Quality + Ball_Control + Second_Chances]\")\n",
        "\n",
        "from pgmpy.models import DiscreteBayesianNetwork\n",
        "\n",
        "# Create the hierarchical Bayesian Network structure\n",
        "hierarchical_model = DiscreteBayesianNetwork([\n",
        "    # Level 1: Intermediate basketball concepts\n",
        "    ('Shooting_FG', 'Shooting_Quality'),\n",
        "    ('Shooting_3PT', 'Shooting_Quality'),\n",
        "    ('Playmaking', 'Ball_Control'),\n",
        "    ('Turnovers', 'Ball_Control'),\n",
        "    ('Offensive_Rebounding', 'Second_Chances'),\n",
        "\n",
        "    # Level 2: Final efficiency\n",
        "    ('Shooting_Quality', 'Efficiency'),\n",
        "    ('Ball_Control', 'Efficiency'),\n",
        "    ('Second_Chances', 'Efficiency')\n",
        "])\n",
        "\n",
        "print(\"‚úÖ HIERARCHICAL NETWORK STRUCTURE CREATED!\")\n",
        "print(f\"üìà Nodes: {hierarchical_model.nodes()}\")\n",
        "print(f\"üìà Edges: {hierarchical_model.edges()}\")\n",
        "\n",
        "print(\"\\nüéØ MATHEMATICAL ADVANTAGE:\")\n",
        "print(\"  ‚Ä¢ 5 raw skills ‚Üí 3 intermediate concepts ‚Üí 1 target\")\n",
        "print(\"  ‚Ä¢ Reduces parameter complexity from 729 to 81\")\n",
        "print(\"  ‚Ä¢ 8.9x more data-efficient learning!\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 3.1 COMPLETED SUCCESSFULLY!\")\n",
        "print(\"üöÄ Ready for Phase 3.2: Learn CPTs with clean data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpKGtar8HLSq",
        "outputId": "0f5802a1-c098-4e07-c464-8542edec6dbb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 3.1: HIERARCHICAL NETWORK STRUCTURE ===\n",
            "üì• Loading final processed data...\n",
            "üìä Dataset shape: (7500, 6)\n",
            "üéØ Columns: ['Efficiency', 'Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Turnovers', 'Offensive_Rebounding']\n",
            "\n",
            "üîç DATA TYPE VERIFICATION:\n",
            "  Efficiency: object - ['Low', 'High', 'Medium']\n",
            "  Shooting_FG: object - ['Low', 'Medium', 'High']\n",
            "  Shooting_3PT: object - ['Low', 'Medium', 'High']\n",
            "  Playmaking: object - ['High', 'Medium', 'Low']\n",
            "  Turnovers: object - ['High', 'Medium', 'Low']\n",
            "  Offensive_Rebounding: object - ['High', 'Medium', 'Low']\n",
            "\n",
            "üîó DESIGNING HIERARCHICAL STRUCTURE...\n",
            "üèÄ BASKETBALL LOGIC:\n",
            "  Level 0: Shooting_FG, Shooting_3PT, Playmaking, Turnovers, Offensive_Rebounding\n",
            "  Level 1: Shooting_Quality ‚Üê [FG + 3PT], Ball_Control ‚Üê [Playmaking - Turnovers]\n",
            "  Level 2: Efficiency ‚Üê [Shooting_Quality + Ball_Control + Second_Chances]\n",
            "‚úÖ HIERARCHICAL NETWORK STRUCTURE CREATED!\n",
            "üìà Nodes: ['Shooting_FG', 'Shooting_Quality', 'Shooting_3PT', 'Playmaking', 'Ball_Control', 'Turnovers', 'Offensive_Rebounding', 'Second_Chances', 'Efficiency']\n",
            "üìà Edges: [('Shooting_FG', 'Shooting_Quality'), ('Shooting_Quality', 'Efficiency'), ('Shooting_3PT', 'Shooting_Quality'), ('Playmaking', 'Ball_Control'), ('Ball_Control', 'Efficiency'), ('Turnovers', 'Ball_Control'), ('Offensive_Rebounding', 'Second_Chances'), ('Second_Chances', 'Efficiency')]\n",
            "\n",
            "üéØ MATHEMATICAL ADVANTAGE:\n",
            "  ‚Ä¢ 5 raw skills ‚Üí 3 intermediate concepts ‚Üí 1 target\n",
            "  ‚Ä¢ Reduces parameter complexity from 729 to 81\n",
            "  ‚Ä¢ 8.9x more data-efficient learning!\n",
            "\n",
            "‚úÖ PHASE 3.1 COMPLETED SUCCESSFULLY!\n",
            "üöÄ Ready for Phase 3.2: Learn CPTs with clean data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3.2: Learn Conditional probability Tables (CPTs)"
      ],
      "metadata": {
        "id": "M7YvaRZfIvi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 3.2 FIXED: BAYESIAN ESTIMATION WITH SMOOTHING ===\n",
        "print(\"=== PHASE 3.2 FIXED: BAYESIAN ESTIMATION WITH SMOOTHING ===\")\n",
        "\n",
        "print(\"üéØ Using Bayesian Estimation for better probability calibration...\")\n",
        "\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "from sklearn.metrics import accuracy_score # Import accuracy_score\n",
        "\n",
        "# Create optimized intermediate variables\n",
        "print(\"üìä Creating optimized intermediate variables...\")\n",
        "hierarchical_data = final_data.copy()\n",
        "\n",
        "def create_optimized_intermediates(data):\n",
        "    \"\"\"Create intermediates with better basketball logic\"\"\"\n",
        "    results = data.copy()\n",
        "\n",
        "    # Use weighted scoring for more precision\n",
        "    score_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "\n",
        "    # Shooting: Weight FG% more than 3PT%\n",
        "    def shooting_quality(row):\n",
        "        fg_score = score_map[row['Shooting_FG']] * 1.5  # Weight FG% more\n",
        "        threept_score = score_map[row['Shooting_3PT']] * 1.0\n",
        "        total = fg_score + threept_score\n",
        "\n",
        "        if total >= 4.5:  # High threshold\n",
        "            return 'High'\n",
        "        elif total <= 1.5:  # Low threshold\n",
        "            return 'Low'\n",
        "        else:\n",
        "            return 'Medium'\n",
        "\n",
        "    # Ball Control: Strong emphasis on turnover avoidance\n",
        "    def ball_control(row):\n",
        "        pm_score = score_map[row['Playmaking']] * 1.0\n",
        "        to_score = (2 - score_map[row['Turnovers']]) * 1.5  # Weight turnovers heavier\n",
        "        total = pm_score + to_score\n",
        "\n",
        "        if total >= 3.5:\n",
        "            return 'High'\n",
        "        elif total <= 1.5:\n",
        "            return 'Low'\n",
        "        else:\n",
        "            return 'Medium'\n",
        "\n",
        "    # Second Chances: Direct but with efficiency guidance\n",
        "    def second_chances(row):\n",
        "        return row['Offensive_Rebounding']  # Keep it simple\n",
        "\n",
        "    results['Shooting_Quality'] = results.apply(shooting_quality, axis=1)\n",
        "    results['Ball_Control'] = results.apply(ball_control, axis=1)\n",
        "    results['Second_Chances'] = results.apply(second_chances, axis=1)\n",
        "\n",
        "    return results\n",
        "\n",
        "hierarchical_data = create_optimized_intermediates(hierarchical_data)\n",
        "\n",
        "print(\"‚úÖ Optimized intermediates created!\")\n",
        "print(f\"üìä Enhanced data shape: {hierarchical_data.shape}\")\n",
        "\n",
        "# Learn CPTs with BAYESIAN ESTIMATION (not MLE)\n",
        "print(\"\\nüéØ LEARNING CPTs WITH BAYESIAN ESTIMATION...\")\n",
        "print(\"   Using BDeu prior for smoother probability estimates...\")\n",
        "\n",
        "hierarchical_model.fit(\n",
        "    hierarchical_data,\n",
        "    estimator=BayesianEstimator,\n",
        "    prior_type='BDeu',\n",
        "    equivalent_sample_size=10  # Smoothing parameter\n",
        ")\n",
        "\n",
        "print(\"‚úÖ CPTs learned with Bayesian smoothing!\")\n",
        "\n",
        "# Create inference engine\n",
        "from pgmpy.inference import VariableElimination\n",
        "inference = VariableElimination(hierarchical_model)\n",
        "\n",
        "# Test accuracy with Bayesian estimation\n",
        "print(\"üìä TESTING BAYESIAN ESTIMATION ACCURACY...\")\n",
        "bayesian_predictions = []\n",
        "bayesian_true = []\n",
        "\n",
        "for idx, row in hierarchical_data.iterrows():\n",
        "    evidence = {\n",
        "        'Shooting_FG': row['Shooting_FG'],\n",
        "        'Shooting_3PT': row['Shooting_3PT'],\n",
        "        'Playmaking': row['Playmaking'],\n",
        "        'Turnovers': row['Turnovers'],\n",
        "        'Offensive_Rebounding': row['Offensive_Rebounding']\n",
        "    }\n",
        "    try:\n",
        "        result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "        predicted = result.state_names['Efficiency'][result.values.argmax()]\n",
        "        bayesian_predictions.append(predicted)\n",
        "        bayesian_true.append(row['Efficiency'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "bayesian_accuracy = accuracy_score(bayesian_true, bayesian_predictions)\n",
        "\n",
        "# Check prediction distribution\n",
        "bayesian_pred_dist = pd.Series(bayesian_predictions).value_counts(normalize=True)\n",
        "\n",
        "print(f\"üéØ BAYESIAN ESTIMATION ACCURACY: {bayesian_accuracy:.1%}\")\n",
        "print(f\"üìä PREDICTION DISTRIBUTION: {dict(bayesian_pred_dist)}\")\n",
        "\n",
        "# Compare with previous approaches\n",
        "print(f\"\\nüìà ACCURACY COMPARISON:\")\n",
        "print(f\"  MLE Hierarchical: 53.9%\")\n",
        "print(f\"  MLE Direct: 58.2%\")\n",
        "print(f\"  BAYESIAN Hierarchical: {bayesian_accuracy:.1%}\")\n",
        "\n",
        "if bayesian_accuracy > 0.582:\n",
        "    improvement = (bayesian_accuracy - 0.582) * 100\n",
        "    print(f\"  ‚úÖ IMPROVEMENT: +{improvement:.1f}%\")\n",
        "\n",
        "# Basketball logic validation\n",
        "print(\"\\nüèÄ BAYESIAN MODEL BASKETBALL LOGIC:\")\n",
        "test_cases = [\n",
        "    (\"Elite Shooting\", {'Shooting_FG': 'High', 'Shooting_3PT': 'High'}),\n",
        "    (\"Great Ball Control\", {'Playmaking': 'High', 'Turnovers': 'Low'}),\n",
        "    (\"Championship Team\", {'Shooting_FG': 'High', 'Shooting_3PT': 'High', 'Playmaking': 'High', 'Turnovers': 'Low', 'Offensive_Rebounding': 'High'})\n",
        "]\n",
        "\n",
        "for name, evidence in test_cases:\n",
        "    result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "    high_prob = result.values[result.state_names['Efficiency'].index('High')]\n",
        "    low_prob = result.values[result.state_names['Efficiency'].index('Low')]\n",
        "    print(f\"  {name}: P(High)={high_prob:.3f}, P(Low)={low_prob:.3f}\")\n",
        "\n",
        "if bayesian_accuracy > 0.65:\n",
        "    print(f\"\\nüéâ SUCCESS! Bayesian estimation achieves {bayesian_accuracy:.1%} accuracy!\")\n",
        "    print(\"üöÄ Ready for Phase 3.3 Validation\")\n",
        "else:\n",
        "    print(f\"\\nüîß Bayesian: {bayesian_accuracy:.1%} - Better but needs more work\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 3.2 FIXED COMPLETED!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s34xZx3EIAj7",
        "outputId": "cd2d58cf-edf6-4572-d602-2047cd8efdbe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pgmpy:Replacing existing CPD for Shooting_FG\n",
            "WARNING:pgmpy:Replacing existing CPD for Shooting_Quality\n",
            "WARNING:pgmpy:Replacing existing CPD for Efficiency\n",
            "WARNING:pgmpy:Replacing existing CPD for Shooting_3PT\n",
            "WARNING:pgmpy:Replacing existing CPD for Playmaking\n",
            "WARNING:pgmpy:Replacing existing CPD for Ball_Control\n",
            "WARNING:pgmpy:Replacing existing CPD for Turnovers\n",
            "WARNING:pgmpy:Replacing existing CPD for Offensive_Rebounding\n",
            "WARNING:pgmpy:Replacing existing CPD for Second_Chances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 3.2 FIXED: BAYESIAN ESTIMATION WITH SMOOTHING ===\n",
            "üéØ Using Bayesian Estimation for better probability calibration...\n",
            "üìä Creating optimized intermediate variables...\n",
            "‚úÖ Optimized intermediates created!\n",
            "üìä Enhanced data shape: (7500, 9)\n",
            "\n",
            "üéØ LEARNING CPTs WITH BAYESIAN ESTIMATION...\n",
            "   Using BDeu prior for smoother probability estimates...\n",
            "‚úÖ CPTs learned with Bayesian smoothing!\n",
            "üìä TESTING BAYESIAN ESTIMATION ACCURACY...\n",
            "üéØ BAYESIAN ESTIMATION ACCURACY: 55.1%\n",
            "üìä PREDICTION DISTRIBUTION: {'Medium': np.float64(0.7221333333333333), 'High': np.float64(0.1552), 'Low': np.float64(0.12266666666666666)}\n",
            "\n",
            "üìà ACCURACY COMPARISON:\n",
            "  MLE Hierarchical: 53.9%\n",
            "  MLE Direct: 58.2%\n",
            "  BAYESIAN Hierarchical: 55.1%\n",
            "\n",
            "üèÄ BAYESIAN MODEL BASKETBALL LOGIC:\n",
            "  Elite Shooting: P(High)=0.429, P(Low)=0.064\n",
            "  Great Ball Control: P(High)=0.288, P(Low)=0.170\n",
            "  Championship Team: P(High)=0.555, P(Low)=0.018\n",
            "\n",
            "üîß Bayesian: 55.1% - Better but needs more work\n",
            "\n",
            "‚úÖ PHASE 3.2 FIXED COMPLETED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3.3: initial Model Validation"
      ],
      "metadata": {
        "id": "ibXNmMExJDI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 3.3: INITIAL MODEL VALIDATION ===\n",
        "print(\"=== PHASE 3.3: INITIAL MODEL VALIDATION ===\")\n",
        "\n",
        "# TEST 1: MARGINAL PROBABILITIES\n",
        "print(\"\\nüìä MARGINAL PROBABILITIES:\")\n",
        "efficiency_marginal = inference.query(variables=['Efficiency'])\n",
        "print(\"Overall Efficiency Distribution:\")\n",
        "for state, prob in zip(efficiency_marginal.state_names['Efficiency'], efficiency_marginal.values):\n",
        "    print(f\"  P({state}): {prob:.3f}\")\n",
        "\n",
        "# TEST 2: REAL-WORLD BASKETBALL SCENARIOS\n",
        "print(\"\\nüèÄ REAL-WORLD SCENARIOS:\")\n",
        "\n",
        "# Championship team (elite everything)\n",
        "print(\"‚≠ê CHAMPIONSHIP TEAM (Elite across the board):\")\n",
        "evidence_champ = {\n",
        "    'Shooting_FG': 'High', 'Shooting_3PT': 'High',\n",
        "    'Playmaking': 'High', 'Turnovers': 'Low',\n",
        "    'Offensive_Rebounding': 'High'\n",
        "}\n",
        "result_champ = inference.query(variables=['Efficiency'], evidence=evidence_champ)\n",
        "champ_high = result_champ.values[result_champ.state_names['Efficiency'].index('High')]\n",
        "print(f\"  P(High Efficiency): {champ_high:.3f}\")\n",
        "\n",
        "# Rebuilding team (poor everything)\n",
        "print(\"\\nüî® REBUILDING TEAM (Poor across the board):\")\n",
        "evidence_rebuild = {\n",
        "    'Shooting_FG': 'Low', 'Shooting_3PT': 'Low',\n",
        "    'Playmaking': 'Low', 'Turnovers': 'High',\n",
        "    'Offensive_Rebounding': 'Low'\n",
        "}\n",
        "result_rebuild = inference.query(variables=['Efficiency'], evidence=evidence_rebuild)\n",
        "rebuild_low = result_rebuild.values[result_rebuild.state_names['Efficiency'].index('Low')]\n",
        "print(f\"  P(Low Efficiency): {rebuild_low:.3f}\")\n",
        "\n",
        "# TEST 3: ACCURACY CHECK\n",
        "print(\"\\nüéØ TRAINING ACCURACY CHECK:\")\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for idx, row in hierarchical_data.iterrows():\n",
        "    evidence = {\n",
        "        'Shooting_FG': row['Shooting_FG'],\n",
        "        'Shooting_3PT': row['Shooting_3PT'],\n",
        "        'Playmaking': row['Playmaking'],\n",
        "        'Turnovers': row['Turnovers'],\n",
        "        'Offensive_Rebounding': row['Offensive_Rebounding']\n",
        "    }\n",
        "    try:\n",
        "        result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "        predicted = result.state_names['Efficiency'][result.values.argmax()]\n",
        "        predictions.append(predicted)\n",
        "        true_labels.append(row['Efficiency'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"üéØ TRAINING ACCURACY: {accuracy:.1%}\")\n",
        "\n",
        "print(\"\\nüìä DETAILED PERFORMANCE:\")\n",
        "print(classification_report(true_labels, predictions, target_names=['High', 'Medium', 'Low']))\n",
        "\n",
        "# Compare with previous attempts\n",
        "print(f\"\\nüìà ACCURACY IMPROVEMENT:\")\n",
        "print(f\"  Previous Best: 54.9%\")\n",
        "print(f\"  Current: {accuracy:.1%}\")\n",
        "if accuracy > 0.549:\n",
        "    improvement = (accuracy - 0.549) * 100\n",
        "    print(f\"  ‚úÖ IMPROVEMENT: +{improvement:.1f}%\")\n",
        "else:\n",
        "    print(f\"  ‚ö†Ô∏è  Still below previous best\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 3.3 COMPLETED!\")\n",
        "if accuracy > 0.60:\n",
        "    print(\"üöÄ EXCELLENT MODEL - Ready for Phase 4!\")\n",
        "else:\n",
        "    print(\"üîß Model needs tuning before Phase 4\")"
      ],
      "metadata": {
        "id": "ohARwRqwI08l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62986e3f-b3b9-443b-c1b0-d2aa33f203a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 3.3: INITIAL MODEL VALIDATION ===\n",
            "\n",
            "üìä MARGINAL PROBABILITIES:\n",
            "Overall Efficiency Distribution:\n",
            "  P(High): 0.209\n",
            "  P(Low): 0.244\n",
            "  P(Medium): 0.547\n",
            "\n",
            "üèÄ REAL-WORLD SCENARIOS:\n",
            "‚≠ê CHAMPIONSHIP TEAM (Elite across the board):\n",
            "  P(High Efficiency): 0.555\n",
            "\n",
            "üî® REBUILDING TEAM (Poor across the board):\n",
            "  P(Low Efficiency): 0.592\n",
            "\n",
            "üéØ TRAINING ACCURACY CHECK:\n",
            "üéØ TRAINING ACCURACY: 55.1%\n",
            "\n",
            "üìä DETAILED PERFORMANCE:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.52      0.36      0.43      1682\n",
            "      Medium       0.55      0.26      0.36      1906\n",
            "         Low       0.56      0.77      0.65      3912\n",
            "\n",
            "    accuracy                           0.55      7500\n",
            "   macro avg       0.54      0.47      0.48      7500\n",
            "weighted avg       0.55      0.55      0.52      7500\n",
            "\n",
            "\n",
            "üìà ACCURACY IMPROVEMENT:\n",
            "  Previous Best: 54.9%\n",
            "  Current: 55.1%\n",
            "  ‚úÖ IMPROVEMENT: +0.2%\n",
            "\n",
            "‚úÖ PHASE 3.3 COMPLETED!\n",
            "üîß Model needs tuning before Phase 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3.4"
      ],
      "metadata": {
        "id": "NMWJLHC-HBiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 3.4 FIXED: ENSEMBLE BAYESIAN NETWORKS ===\n",
        "print(\"=== PHASE 3.4 FIXED: ENSEMBLE BAYESIAN NETWORKS ===\\n\")\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pgmpy.models import BayesianNetwork, DiscreteBayesianNetwork # Import DiscreteBayesianNetwork\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "from pgmpy.inference import VariableElimination # Import VariableElimination\n",
        "\n",
        "# Load and prepare data\n",
        "print(\"üì• Preparing data for ensemble training...\")\n",
        "data = pd.read_csv('nba_lineup_efficiency_final_data.csv')\n",
        "\n",
        "# Convert to proper categorical with consistent ordering\n",
        "for col in data.columns:\n",
        "    data[col] = pd.Categorical(data[col], categories=['Low', 'Medium', 'High'], ordered=True)\n",
        "\n",
        "print(\"üîß CREATING INTERMEDIATE VARIABLES FOR HIERARCHICAL MODELS...\")\n",
        "\n",
        "# Create intermediate variables for hierarchical models\n",
        "def create_intermediate_variables(df):\n",
        "    \"\"\"Create Shooting_Quality, Ball_Control, and Second_Chances variables\"\"\"\n",
        "    df_extended = df.copy()\n",
        "\n",
        "    # Define scoring for each level\n",
        "    score_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "\n",
        "    # Shooting Quality: Combine FG% and 3PT%\n",
        "    def get_shooting_quality(row):\n",
        "        fg_score = score_map[row['Shooting_FG']]\n",
        "        threept_score = score_map[row['Shooting_3PT']]\n",
        "        total_score = fg_score + threept_score\n",
        "\n",
        "        if total_score >= 3:  # High + High = 4, High + Medium = 3\n",
        "            return 'High'\n",
        "        elif total_score <= 1:  # Low + Low = 0, Low + Medium = 1\n",
        "            return 'Low'\n",
        "        else:\n",
        "            return 'Medium'\n",
        "\n",
        "    # Ball Control: Playmaking minus Turnovers (lower turnovers = better)\n",
        "    def get_ball_control(row):\n",
        "        playmaking_score = score_map[row['Playmaking']]\n",
        "        # Invert turnovers: High turnovers = bad, Low turnovers = good\n",
        "        turnover_score = 2 - score_map[row['Turnovers']]  # Invert the score\n",
        "        total_score = playmaking_score + turnover_score\n",
        "\n",
        "        if total_score >= 3:\n",
        "            return 'High'\n",
        "        elif total_score <= 1:\n",
        "            return 'Low'\n",
        "        else:\n",
        "            return 'Medium'\n",
        "\n",
        "    # Second Chances: Direct mapping from offensive rebounding\n",
        "    def get_second_chances(row):\n",
        "        return row['Offensive_Rebounding']\n",
        "\n",
        "    # Apply the functions\n",
        "    df_extended['Shooting_Quality'] = df_extended.apply(get_shooting_quality, axis=1)\n",
        "    df_extended['Ball_Control'] = df_extended.apply(get_ball_control, axis=1)\n",
        "    df_extended['Second_Chances'] = df_extended.apply(get_second_chances, axis=1)\n",
        "\n",
        "    # Convert to categorical\n",
        "    df_extended['Shooting_Quality'] = pd.Categorical(df_extended['Shooting_Quality'],\n",
        "                                                   categories=['Low', 'Medium', 'High'], ordered=True)\n",
        "    df_extended['Ball_Control'] = pd.Categorical(df_extended['Ball_Control'],\n",
        "                                               categories=['Low', 'Medium', 'High'], ordered=True)\n",
        "    df_extended['Second_Chances'] = pd.Categorical(df_extended['Second_Chances'],\n",
        "                                                 categories=['Low', 'Medium', 'High'], ordered=True)\n",
        "\n",
        "    return df_extended\n",
        "\n",
        "# Create extended dataset with intermediate variables *before* splitting\n",
        "extended_data = create_intermediate_variables(data)\n",
        "print(\"‚úÖ Intermediate variables created!\")\n",
        "print(f\"üìä Extended dataset columns: {list(extended_data.columns)}\")\n",
        "\n",
        "# Split data for proper validation (use extended_data)\n",
        "train_data, test_data = train_test_split(extended_data, test_size=0.2, random_state=42, stratify=extended_data['Efficiency'])\n",
        "print(f\"üìä Training samples: {len(train_data)}, Test samples: {len(test_data)}\")\n",
        "\n",
        "# Define multiple network structures\n",
        "print(\"\\nüîß CREATING ENSEMBLE OF BAYESIAN NETWORKS...\")\n",
        "\n",
        "ensemble_models = {}\n",
        "\n",
        "# Model 1: Direct relationships (simplest)\n",
        "model1 = DiscreteBayesianNetwork([ # Use DiscreteBayesianNetwork\n",
        "    ('Shooting_FG', 'Efficiency'),\n",
        "    ('Shooting_3PT', 'Efficiency'),\n",
        "    ('Playmaking', 'Efficiency'),\n",
        "    ('Turnovers', 'Efficiency'),\n",
        "    ('Offensive_Rebounding', 'Efficiency')\n",
        "])\n",
        "ensemble_models['Direct_Model'] = model1\n",
        "\n",
        "# Model 2: Hierarchical with shooting focus\n",
        "model2 = DiscreteBayesianNetwork([ # Use DiscreteBayesianNetwork\n",
        "    ('Shooting_FG', 'Shooting_Quality'),\n",
        "    ('Shooting_3PT', 'Shooting_Quality'),\n",
        "    ('Shooting_Quality', 'Efficiency'),\n",
        "    ('Playmaking', 'Efficiency'),\n",
        "    ('Turnovers', 'Efficiency'),\n",
        "    ('Offensive_Rebounding', 'Efficiency')\n",
        "])\n",
        "ensemble_models['Shooting_Hierarchical'] = model2\n",
        "\n",
        "# Model 3: Playmaking focused hierarchy\n",
        "model3 = DiscreteBayesianNetwork([ # Use DiscreteBayesianNetwork\n",
        "    ('Playmaking', 'Ball_Control'),\n",
        "    ('Turnovers', 'Ball_Control'),\n",
        "    ('Ball_Control', 'Efficiency'),\n",
        "    ('Shooting_FG', 'Efficiency'),\n",
        "    ('Shooting_3PT', 'Efficiency'),\n",
        "    ('Offensive_Rebounding', 'Efficiency')\n",
        "])\n",
        "ensemble_models['Playmaking_Hierarchical'] = model3\n",
        "\n",
        "# Model 4: Full hierarchy (your original approach)\n",
        "model4 = DiscreteBayesianNetwork([ # Use DiscreteBayesianNetwork\n",
        "    ('Shooting_FG', 'Shooting_Quality'),\n",
        "    ('Shooting_3PT', 'Shooting_Quality'),\n",
        "    ('Playmaking', 'Ball_Control'),\n",
        "    ('Turnovers', 'Ball_Control'),\n",
        "    ('Offensive_Rebounding', 'Second_Chances'),\n",
        "    ('Shooting_Quality', 'Efficiency'),\n",
        "    ('Ball_Control', 'Efficiency'),\n",
        "    ('Second_Chances', 'Efficiency')\n",
        "])\n",
        "ensemble_models['Full_Hierarchy'] = model4\n",
        "\n",
        "# Model 5: Correlation-based structure (using actual data correlations)\n",
        "model5 = DiscreteBayesianNetwork([ # Use DiscreteBayesianNetwork\n",
        "    ('Shooting_FG', 'Efficiency'),      # Strongest correlation\n",
        "    ('Playmaking', 'Efficiency'),       # Second strongest\n",
        "    ('Shooting_3PT', 'Efficiency'),     # Third strongest\n",
        "    ('Turnovers', 'Efficiency'),        # Negative correlation\n",
        "    ('Offensive_Rebounding', 'Turnovers')  # Weak but meaningful\n",
        "])\n",
        "ensemble_models['Correlation_Based'] = model5\n",
        "\n",
        "# Model 6: Minimal high-impact features only\n",
        "model6 = DiscreteBayesianNetwork([ # Use DiscreteBayesianNetwork\n",
        "    ('Shooting_FG', 'Efficiency'),      # Strongest positive correlation\n",
        "    ('Turnovers', 'Efficiency'),        # Strongest negative correlation\n",
        "    ('Playmaking', 'Efficiency'),       # Second strongest positive\n",
        "])\n",
        "ensemble_models['Minimal_Model'] = model6\n",
        "\n",
        "\n",
        "print(f\"‚úÖ Created {len(ensemble_models)} different Bayesian network structures\")\n",
        "\n",
        "# Train all models and evaluate their performance\n",
        "print(\"\\nüéØ TRAINING AND EVALUATING ENSEMBLE MODELS...\")\n",
        "\n",
        "model_performances = {}\n",
        "trained_models = {}\n",
        "\n",
        "for model_name, model in ensemble_models.items():\n",
        "    print(f\"\\nüîß Training {model_name}...\")\n",
        "\n",
        "    try:\n",
        "        # Check if all nodes exist in data\n",
        "        required_nodes = set(model.nodes())\n",
        "        available_nodes = set(train_data.columns)\n",
        "\n",
        "        if not required_nodes.issubset(available_nodes):\n",
        "            missing_nodes = required_nodes - available_nodes\n",
        "            print(f\"   ‚ö†Ô∏è  Missing nodes: {missing_nodes}. Skipping...\")\n",
        "            model_performances[model_name] = 0\n",
        "            continue\n",
        "\n",
        "\n",
        "        # Fit the model with appropriate data subset\n",
        "        model.fit(train_data, estimator=BayesianEstimator, equivalent_sample_size=3)\n",
        "        trained_models[model_name] = model\n",
        "\n",
        "        # Create inference engine\n",
        "        inference = VariableElimination(model)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        for idx, row in test_data.iterrows():\n",
        "            # Create evidence with only the nodes this model needs\n",
        "            evidence = {}\n",
        "            for node in model.nodes():\n",
        "                if node != 'Efficiency' and node in row:\n",
        "                    evidence[node] = row[node]\n",
        "\n",
        "            try:\n",
        "                result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "                predicted = result.state_names['Efficiency'][np.argmax(result.values)]\n",
        "                predictions.append(predicted)\n",
        "                true_labels.append(row['Efficiency'])\n",
        "            except Exception as e:\n",
        "                # If inference fails, use the most common class as fallback\n",
        "                predictions.append('Medium')\n",
        "                true_labels.append(row['Efficiency'])\n",
        "                continue\n",
        "\n",
        "        accuracy = accuracy_score(true_labels, predictions)\n",
        "        model_performances[model_name] = accuracy\n",
        "        print(f\"   ‚úÖ {model_name} Accuracy: {accuracy:.1%}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå {model_name} failed: {e}\")\n",
        "        model_performances[model_name] = 0\n",
        "\n",
        "\n",
        "print(\"\\nüìä ENSEMBLE PERFORMANCE SUMMARY:\")\n",
        "for model_name, accuracy in sorted(model_performances.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"   {model_name}: {accuracy:.1%}\")\n",
        "\n",
        "# Select the best model\n",
        "best_model_name = max(model_performances, key=model_performances.get)\n",
        "best_model = trained_models.get(best_model_name) # Use .get to handle cases where a model failed training\n",
        "best_accuracy = model_performances[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name} ({best_accuracy:.1%} accuracy)\")\n",
        "\n",
        "# Create ensemble predictions (majority voting) only from successful models\n",
        "print(\"\\nü§ù CREATING ENSEMBLE PREDICTIONS (Majority Voting)...\")\n",
        "\n",
        "def ensemble_predict(evidence_data, models_dict, performances_dict):\n",
        "    \"\"\"Get ensemble prediction using weighted voting\"\"\"\n",
        "    all_predictions = []\n",
        "    valid_models = []\n",
        "\n",
        "    for model_name, model in models_dict.items():\n",
        "        if model_name in performances_dict and performances_dict[model_name] > 0.5: # Only use decent models\n",
        "            try:\n",
        "                inference = VariableElimination(model)\n",
        "                predictions = []\n",
        "\n",
        "                for idx, row in evidence_data.iterrows():\n",
        "                    evidence = {}\n",
        "                    for node in model.nodes():\n",
        "                        if node != 'Efficiency' and node in row: # Ensure node is in the evidence data\n",
        "                             evidence[node] = row[node]\n",
        "\n",
        "                    result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "                    predicted = result.state_names['Efficiency'][np.argmax(result.values)]\n",
        "                    predictions.append(predicted)\n",
        "\n",
        "                all_predictions.append(predictions)\n",
        "                valid_models.append(model_name)\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if not all_predictions:\n",
        "        print(\"   ‚ö†Ô∏è  No valid models for ensemble prediction\")\n",
        "        return None\n",
        "\n",
        "    print(f\"   ‚úÖ Using {len(valid_models)} models: {valid_models}\")\n",
        "\n",
        "    # Weighted majority voting based on individual model performance\n",
        "    ensemble_final = []\n",
        "    for i in range(len(evidence_data)):\n",
        "        votes = {'Low': 0, 'Medium': 0, 'High': 0}\n",
        "        for j, pred_list in enumerate(all_predictions):\n",
        "            model_name = valid_models[j]\n",
        "            weight = performances_dict.get(model_name, 0.5) # Use accuracy as weight\n",
        "            votes[pred_list[i]] += weight\n",
        "\n",
        "        # Select the class with highest weighted votes\n",
        "        winner = max(votes.items(), key=lambda x: x[1])[0]\n",
        "        ensemble_final.append(winner)\n",
        "\n",
        "    return ensemble_final\n",
        "\n",
        "# Test ensemble performance\n",
        "ensemble_predictions = ensemble_predict(test_data, trained_models, model_performances)\n",
        "if ensemble_predictions:\n",
        "    ensemble_accuracy = accuracy_score(test_data['Efficiency'], ensemble_predictions)\n",
        "    print(f\"üéØ ENSEMBLE ACCURACY: {ensemble_accuracy:.1%}\")\n",
        "\n",
        "    print(f\"\\nüìà PERFORMANCE COMPARISON:\")\n",
        "    print(f\"  Single Best Model: {best_accuracy:.1%}\")\n",
        "    print(f\"  Ensemble Method: {ensemble_accuracy:.1%}\")\n",
        "    improvement = (ensemble_accuracy - best_accuracy) * 100\n",
        "    print(f\"  üìà ENSEMBLE IMPROVEMENT: +{improvement:.1f}%\")\n",
        "else:\n",
        "    print(\"‚ùå Ensemble prediction failed\")\n",
        "\n",
        "\n",
        "# Save the best performing models\n",
        "import pickle\n",
        "if trained_models: # Only save if at least one model trained successfully\n",
        "    ensemble_data = {\n",
        "        'models': trained_models,\n",
        "        'performances': model_performances,\n",
        "        'best_model': best_model_name,\n",
        "        'ensemble_accuracy': ensemble_accuracy if ensemble_predictions else best_accuracy # Save ensemble accuracy if available\n",
        "    }\n",
        "\n",
        "    with open('bayesian_ensemble_fixed.pkl', 'wb') as f:\n",
        "        pickle.dump(ensemble_data, f)\n",
        "\n",
        "    print(\"üíæ Saved ensemble models as 'bayesian_ensemble_fixed.pkl'\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 3.4 FIXED COMPLETED!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5w_kjNxG43o",
        "outputId": "c0fda9df-e4ab-4a78-a1cd-d95d96ad42fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 3.4 FIXED: ENSEMBLE BAYESIAN NETWORKS ===\n",
            "\n",
            "üì• Preparing data for ensemble training...\n",
            "üîß CREATING INTERMEDIATE VARIABLES FOR HIERARCHICAL MODELS...\n",
            "‚úÖ Intermediate variables created!\n",
            "üìä Extended dataset columns: ['Efficiency', 'Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Turnovers', 'Offensive_Rebounding', 'Shooting_Quality', 'Ball_Control', 'Second_Chances']\n",
            "üìä Training samples: 6000, Test samples: 1500\n",
            "\n",
            "üîß CREATING ENSEMBLE OF BAYESIAN NETWORKS...\n",
            "‚úÖ Created 6 different Bayesian network structures\n",
            "\n",
            "üéØ TRAINING AND EVALUATING ENSEMBLE MODELS...\n",
            "\n",
            "üîß Training Direct_Model...\n",
            "   ‚úÖ Direct_Model Accuracy: 55.4%\n",
            "\n",
            "üîß Training Shooting_Hierarchical...\n",
            "   ‚úÖ Shooting_Hierarchical Accuracy: 53.4%\n",
            "\n",
            "üîß Training Playmaking_Hierarchical...\n",
            "   ‚úÖ Playmaking_Hierarchical Accuracy: 56.6%\n",
            "\n",
            "üîß Training Full_Hierarchy...\n",
            "   ‚úÖ Full_Hierarchy Accuracy: 55.7%\n",
            "\n",
            "üîß Training Correlation_Based...\n",
            "   ‚úÖ Correlation_Based Accuracy: 56.1%\n",
            "\n",
            "üîß Training Minimal_Model...\n",
            "   ‚úÖ Minimal_Model Accuracy: 56.8%\n",
            "\n",
            "üìä ENSEMBLE PERFORMANCE SUMMARY:\n",
            "   Minimal_Model: 56.8%\n",
            "   Playmaking_Hierarchical: 56.6%\n",
            "   Correlation_Based: 56.1%\n",
            "   Full_Hierarchy: 55.7%\n",
            "   Direct_Model: 55.4%\n",
            "   Shooting_Hierarchical: 53.4%\n",
            "\n",
            "üèÜ BEST MODEL: Minimal_Model (56.8% accuracy)\n",
            "\n",
            "ü§ù CREATING ENSEMBLE PREDICTIONS (Majority Voting)...\n",
            "   ‚úÖ Using 6 models: ['Direct_Model', 'Shooting_Hierarchical', 'Playmaking_Hierarchical', 'Full_Hierarchy', 'Correlation_Based', 'Minimal_Model']\n",
            "üéØ ENSEMBLE ACCURACY: 56.8%\n",
            "\n",
            "üìà PERFORMANCE COMPARISON:\n",
            "  Single Best Model: 56.8%\n",
            "  Ensemble Method: 56.8%\n",
            "  üìà ENSEMBLE IMPROVEMENT: +0.0%\n",
            "üíæ Saved ensemble models as 'bayesian_ensemble_fixed.pkl'\n",
            "\n",
            "‚úÖ PHASE 3.4 FIXED COMPLETED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phase 3.5"
      ],
      "metadata": {
        "id": "jx95-27BHNVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PHASE 3.5: ADVANCED ENSEMBLE WITH PROBABILITY FUSION ===\n",
        "print(\"=== PHASE 3.5: ADVANCED ENSEMBLE WITH PROBABILITY FUSION ===\\n\")\n",
        "\n",
        "print(\"üîß IMPLEMENTING PROBABILITY-BASED ENSEMBLE FUSION...\")\n",
        "\n",
        "def probability_fusion_ensemble(evidence_data, models_dict, performances_dict):\n",
        "    \"\"\"Advanced ensemble using probability fusion instead of hard voting\"\"\"\n",
        "    all_probabilities = []\n",
        "    model_weights = []\n",
        "\n",
        "    for model_name, model in models_dict.items():\n",
        "        if model_name in performances_dict and performances_dict[model_name] > 0:\n",
        "            try:\n",
        "                inference = VariableElimination(model)\n",
        "                model_probs = []\n",
        "\n",
        "                for idx, row in evidence_data.iterrows():\n",
        "                    evidence = {col: row[col] for col in model.nodes() if col != 'Efficiency'}\n",
        "                    result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "\n",
        "                    # Get probability distribution\n",
        "                    prob_dict = {\n",
        "                        'Low': result.values[result.state_names['Efficiency'].index('Low')],\n",
        "                        'Medium': result.values[result.state_names['Efficiency'].index('Medium')],\n",
        "                        'High': result.values[result.state_names['Efficiency'].index('High')]\n",
        "                    }\n",
        "                    model_probs.append(prob_dict)\n",
        "\n",
        "                all_probabilities.append(model_probs)\n",
        "                model_weights.append(performances_dict[model_name])  # Use accuracy as weight\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è {model_name} probability fusion failed: {e}\")\n",
        "                continue\n",
        "\n",
        "    if not all_probabilities:\n",
        "        return None\n",
        "\n",
        "    # Weighted probability fusion\n",
        "    final_predictions = []\n",
        "    for i in range(len(evidence_data)):\n",
        "        fused_probs = {'Low': 0, 'Medium': 0, 'High': 0}\n",
        "        total_weight = sum(model_weights)\n",
        "\n",
        "        for j, probs_list in enumerate(all_probabilities):\n",
        "            weight = model_weights[j] / total_weight  # Normalize weights\n",
        "            for state in ['Low', 'Medium', 'High']:\n",
        "                fused_probs[state] += probs_list[i][state] * weight\n",
        "\n",
        "        # Select class with highest fused probability\n",
        "        winner = max(fused_probs.items(), key=lambda x: x[1])[0]\n",
        "        final_predictions.append(winner)\n",
        "\n",
        "    return final_predictions\n",
        "\n",
        "# Test probability fusion ensemble\n",
        "print(\"üéØ TESTING PROBABILITY FUSION ENSEMBLE...\")\n",
        "fusion_predictions = probability_fusion_ensemble(test_data, trained_models, model_performances)\n",
        "\n",
        "if fusion_predictions:\n",
        "    fusion_accuracy = accuracy_score(test_data['Efficiency'], fusion_predictions)\n",
        "    print(f\"üéØ PROBABILITY FUSION ACCURACY: {fusion_accuracy:.1%}\")\n",
        "\n",
        "print(f\"\\\\nüìä FINAL ENSEMBLE COMPARISON:\")\n",
        "print(f\"  Single Best Model: {best_accuracy:.1%}\")\n",
        "print(f\"  Majority Voting Ensemble: {ensemble_accuracy:.1%}\")\n",
        "print(f\"  Probability Fusion Ensemble: {fusion_accuracy:.1%}\")\n",
        "\n",
        "# Test on challenging cases\n",
        "print(\"\\nüèÄ TESTING ON CHALLENGING BASKETBALL SCENARIOS...\")\n",
        "\n",
        "test_cases = [\n",
        "    {\n",
        "        'name': 'Elite Shooting, Poor Defense',\n",
        "        'evidence': {'Shooting_FG': 'High', 'Shooting_3PT': 'High', 'Playmaking': 'Low', 'Turnovers': 'High', 'Offensive_Rebounding': 'Low'}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Great Defense, Poor Offense',\n",
        "        'evidence': {'Shooting_FG': 'Low', 'Shooting_3PT': 'Low', 'Playmaking': 'High', 'Turnovers': 'Low', 'Offensive_Rebounding': 'High'}\n",
        "    },\n",
        "    {\n",
        "        'name': 'Balanced Team',\n",
        "        'evidence': {'Shooting_FG': 'Medium', 'Shooting_3PT': 'Medium', 'Playmaking': 'Medium', 'Turnovers': 'Medium', 'Offensive_Rebounding': 'Medium'}\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"\\\\nüîç ENSEMBLE PREDICTIONS FOR TEST CASES:\")\n",
        "for case in test_cases:\n",
        "    # Convert to DataFrame for ensemble prediction\n",
        "    case_df = pd.DataFrame([case['evidence']])\n",
        "\n",
        "    ensemble_pred = ensemble_predict(case_df, trained_models, model_performances)\n",
        "    fusion_pred = probability_fusion_ensemble(case_df, trained_models, model_performances)\n",
        "\n",
        "    print(f\"\\\\n  {case['name']}:\")\n",
        "    print(f\"    Evidence: {case['evidence']}\")\n",
        "    print(f\"    Majority Voting: {ensemble_pred[0] if ensemble_pred else 'N/A'}\")\n",
        "    print(f\"    Probability Fusion: {fusion_pred[0] if fusion_pred else 'N/A'}\")\n",
        "\n",
        "# Feature importance analysis\n",
        "print(\"\\nüìà FEATURE IMPORTANCE ANALYSIS...\")\n",
        "\n",
        "def analyze_feature_importance(model, feature_names):\n",
        "    \"\"\"Analyze how features affect efficiency predictions\"\"\"\n",
        "    importance_scores = {}\n",
        "\n",
        "    for feature in feature_names:\n",
        "        if feature != 'Efficiency':\n",
        "            # Test probability changes when feature changes\n",
        "            base_evidence = {f: 'Medium' for f in feature_names if f != 'Efficiency'}\n",
        "\n",
        "            # Query with feature set to Low\n",
        "            base_evidence[feature] = 'Low'\n",
        "            result_low = model.query(variables=['Efficiency'], evidence=base_evidence)\n",
        "            prob_low_high = result_low.values[result_low.state_names['Efficiency'].index('High')]\n",
        "\n",
        "            # Query with feature set to High\n",
        "            base_evidence[feature] = 'High'\n",
        "            result_high = model.query(variables=['Efficiency'], evidence=base_evidence)\n",
        "            prob_high_high = result_high.values[result_high.state_names['Efficiency'].index('High')]\n",
        "\n",
        "            # Importance = probability difference\n",
        "            importance = abs(prob_high_high - prob_low_high)\n",
        "            importance_scores[feature] = importance\n",
        "\n",
        "    return importance_scores\n",
        "\n",
        "# Analyze best model's feature importance\n",
        "if best_model_name in trained_models:\n",
        "    features = [node for node in best_model.nodes() if node != 'Efficiency']\n",
        "    importance = analyze_feature_importance(VariableElimination(best_model), features)\n",
        "\n",
        "    print(\"üîç FEATURE IMPORTANCE IN BEST MODEL:\")\n",
        "    for feature, score in sorted(importance.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"   {feature}: {score:.3f}\")\n",
        "\n",
        "print(\"\\\\n‚úÖ PHASE 3.5 COMPLETED!\")\n",
        "print(\"üöÄ ENSEMBLE METHOD READY FOR DEPLOYMENT!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFoBZBNYHd96",
        "outputId": "dd0b97a4-0ba2-4d75-eed0-b860fbffd4af"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PHASE 3.5: ADVANCED ENSEMBLE WITH PROBABILITY FUSION ===\n",
            "\n",
            "üîß IMPLEMENTING PROBABILITY-BASED ENSEMBLE FUSION...\n",
            "üéØ TESTING PROBABILITY FUSION ENSEMBLE...\n",
            "üéØ PROBABILITY FUSION ACCURACY: 56.9%\n",
            "\\nüìä FINAL ENSEMBLE COMPARISON:\n",
            "  Single Best Model: 56.1%\n",
            "  Majority Voting Ensemble: 56.1%\n",
            "  Probability Fusion Ensemble: 56.9%\n",
            "\n",
            "üèÄ TESTING ON CHALLENGING BASKETBALL SCENARIOS...\n",
            "\\nüîç ENSEMBLE PREDICTIONS FOR TEST CASES:\n",
            "\\n  Elite Shooting, Poor Defense:\n",
            "    Evidence: {'Shooting_FG': 'High', 'Shooting_3PT': 'High', 'Playmaking': 'Low', 'Turnovers': 'High', 'Offensive_Rebounding': 'Low'}\n",
            "    Majority Voting: Medium\n",
            "    Probability Fusion: Medium\n",
            "\\n  Great Defense, Poor Offense:\n",
            "    Evidence: {'Shooting_FG': 'Low', 'Shooting_3PT': 'Low', 'Playmaking': 'High', 'Turnovers': 'Low', 'Offensive_Rebounding': 'High'}\n",
            "    Majority Voting: Medium\n",
            "    Probability Fusion: Medium\n",
            "\\n  Balanced Team:\n",
            "    Evidence: {'Shooting_FG': 'Medium', 'Shooting_3PT': 'Medium', 'Playmaking': 'Medium', 'Turnovers': 'Medium', 'Offensive_Rebounding': 'Medium'}\n",
            "    Majority Voting: High\n",
            "    Probability Fusion: High\n",
            "\n",
            "üìà FEATURE IMPORTANCE ANALYSIS...\n",
            "üîç FEATURE IMPORTANCE IN BEST MODEL:\n",
            "   Turnovers: 0.475\n",
            "   Playmaking: 0.422\n",
            "   Shooting_3PT: 0.076\n",
            "   Shooting_FG: 0.017\n",
            "   Offensive_Rebounding: 0.000\n",
            "\\n‚úÖ PHASE 3.5 COMPLETED!\n",
            "üöÄ ENSEMBLE METHOD READY FOR DEPLOYMENT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# NBA LINEUP EFFICIENCY BAYESIAN NETWORK - OPTIMIZED\n",
        "# ==================================================\n",
        "\n",
        "# Install required packages\n",
        "!pip install pgmpy pandas numpy matplotlib seaborn networkx nba_api scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pgmpy.models import BayesianNetwork\n",
        "from pgmpy.estimators import BayesianEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Packages imported successfully!\")\n",
        "\n",
        "# ==================================================\n",
        "# PHASE 1: DATA ACQUISITION & INTEGRATION (KEEPING WORKING PART)\n",
        "# ==================================================\n",
        "\n",
        "print(\"üöÄ GETTING REAL NBA LINEUP DATA FROM OFFICIAL NBA API...\")\n",
        "\n",
        "from nba_api.stats.endpoints import teamdashlineups\n",
        "from nba_api.stats.static import teams\n",
        "import time\n",
        "\n",
        "# Get all NBA teams\n",
        "nba_teams = teams.get_teams()\n",
        "team_dict = {team['full_name']: team['id'] for team in nba_teams}\n",
        "\n",
        "print(f\"‚úÖ Found {len(team_dict)} NBA teams\")\n",
        "\n",
        "# Function to get lineups for a team\n",
        "def get_lineups(team_id_i):\n",
        "    try:\n",
        "        lineup = teamdashlineups.TeamDashLineups(\n",
        "            team_id=team_id_i,\n",
        "            season='2023-24',\n",
        "            season_type_all_star='Regular Season',\n",
        "            group_quantity=5,\n",
        "            per_mode_detailed='Totals'\n",
        "        )\n",
        "        df = lineup.get_data_frames()\n",
        "        return df[1]  # Lineup data\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error getting lineups for team {team_id_i}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Get lineups for all teams\n",
        "print(\"\\nüì• DOWNLOADING LINEUP DATA FOR ALL TEAMS...\")\n",
        "dataframes = []\n",
        "\n",
        "for i, team_name in enumerate(team_dict.keys()):\n",
        "    team_id_i = team_dict[team_name]\n",
        "    print(f\"   {i+1}/{len(team_dict)}: Getting {team_name}...\")\n",
        "\n",
        "    team_lineup = get_lineups(team_id_i)\n",
        "    if team_lineup is not None and not team_lineup.empty:\n",
        "        team_lineup['team'] = team_name\n",
        "        team_lineup['team_id'] = team_id_i\n",
        "        dataframes.append(team_lineup)\n",
        "\n",
        "    time.sleep(0.5)  # Rate limiting\n",
        "\n",
        "# Combine all team lineups\n",
        "if dataframes:\n",
        "    league_lineup = pd.concat(dataframes, ignore_index=True)\n",
        "    league_lineup['players_list'] = league_lineup['GROUP_NAME'].str.split(' - ')\n",
        "\n",
        "    print(f\"\\n‚úÖ SUCCESS: Downloaded {len(league_lineup)} lineup combinations!\")\n",
        "    league_lineup.to_csv('nba_lineups_2024_api.csv', index=False)\n",
        "\n",
        "    # Show sample\n",
        "    print(\"\\nüîç SAMPLE OF REAL NBA LINEUP DATA:\")\n",
        "    display(league_lineup[['GROUP_NAME', 'team', 'MIN', 'PLUS_MINUS', 'FG_PCT', 'FG3_PCT']].head(3))\n",
        "else:\n",
        "    print(\"‚ùå No lineup data could be downloaded\")\n",
        "\n",
        "# ==================================================\n",
        "# PHASE 2: NEW DATA PROCESSING APPROACH\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n=== PHASE 2: OPTIMIZED DATA PROCESSING ===\")\n",
        "\n",
        "# Load the data\n",
        "lineup_data = pd.read_csv('nba_lineups_2024_api.csv')\n",
        "print(f\"üìä Original data shape: {lineup_data.shape}\")\n",
        "\n",
        "# Create rate-based features (per 48 minutes)\n",
        "def create_advanced_features(data):\n",
        "    df = data.copy()\n",
        "    minutes = df['MIN']\n",
        "\n",
        "    # Efficiency metrics\n",
        "    df['Efficiency'] = df['PLUS_MINUS']\n",
        "\n",
        "    # Shooting metrics (already percentages)\n",
        "    df['Shooting_FG'] = df['FG_PCT']\n",
        "    df['Shooting_3PT'] = df['FG3_PCT']\n",
        "\n",
        "    # Playmaking and ball control (per 48 min)\n",
        "    df['Playmaking'] = (df['AST'] / minutes) * 48\n",
        "    df['Turnovers'] = (df['TOV'] / minutes) * 48\n",
        "\n",
        "    # Rebounding and defense (per 48 min)\n",
        "    df['Offensive_Rebounding'] = (df['OREB'] / minutes) * 48\n",
        "    df['Defensive_Rebounding'] = (df['DREB'] / minutes) * 48\n",
        "\n",
        "    return df[['Efficiency', 'Shooting_FG', 'Shooting_3PT',\n",
        "               'Playmaking', 'Turnovers', 'Offensive_Rebounding', 'Defensive_Rebounding']]\n",
        "\n",
        "# Create advanced features\n",
        "advanced_data = create_advanced_features(lineup_data)\n",
        "advanced_data = advanced_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "print(f\"üìä Advanced features shape: {advanced_data.shape}\")\n",
        "\n",
        "# Check correlations\n",
        "print(\"\\nüìä FEATURE CORRELATIONS WITH EFFICIENCY:\")\n",
        "correlations = advanced_data.corr()['Efficiency'].sort_values(ascending=False)\n",
        "for feature, corr in correlations.items():\n",
        "    if feature != 'Efficiency':\n",
        "        print(f\"   {feature}: {corr:.3f}\")\n",
        "\n",
        "# ==================================================\n",
        "# NEW DISCRETIZATION STRATEGY\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\nüîß SMART DISCRETIZATION WITH QUANTILES...\")\n",
        "\n",
        "def smart_discretize(data):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Use quantile-based discretization for better distribution\n",
        "    discretized_data = pd.DataFrame()\n",
        "\n",
        "    # Efficiency: Use basketball-informed thresholds\n",
        "    discretized_data['Efficiency'] = pd.cut(df['Efficiency'],\n",
        "                                          bins=[-float('inf'), -3, 3, float('inf')],\n",
        "                                          labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "    # Shooting: Use performance-based quantiles\n",
        "    discretized_data['Shooting_FG'] = pd.qcut(df['Shooting_FG'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "    discretized_data['Shooting_3PT'] = pd.qcut(df['Shooting_3PT'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "    # Playmaking and turnovers: Use rate-based quantiles\n",
        "    discretized_data['Playmaking'] = pd.qcut(df['Playmaking'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "    discretized_data['Turnovers'] = pd.qcut(df['Turnovers'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "    # Rebounding: Use rate-based quantiles\n",
        "    discretized_data['Offensive_Rebounding'] = pd.qcut(df['Offensive_Rebounding'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "    discretized_data['Defensive_Rebounding'] = pd.qcut(df['Defensive_Rebounding'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "    return discretized_data\n",
        "\n",
        "# Apply discretization\n",
        "final_data = smart_discretize(advanced_data)\n",
        "print(f\"üìä Discretized data shape: {final_data.shape}\")\n",
        "\n",
        "# Check distribution\n",
        "print(\"\\nüìä DISCRETIZED DISTRIBUTION:\")\n",
        "for col in final_data.columns:\n",
        "    dist = final_data[col].value_counts(normalize=True)\n",
        "    print(f\"{col}: {dict(dist)}\")\n",
        "\n",
        "# Save processed data\n",
        "final_data.to_csv('optimized_nba_data.csv', index=False)\n",
        "print(\"üíæ Saved optimized data\")\n",
        "\n",
        "# ==================================================\n",
        "# PHASE 3: NEW BAYESIAN NETWORK STRUCTURE\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n=== PHASE 3: OPTIMIZED BAYESIAN NETWORK ===\")\n",
        "\n",
        "# Load processed data\n",
        "final_data = pd.read_csv('optimized_nba_data.csv')\n",
        "print(f\"üìä Training data: {final_data.shape}\")\n",
        "\n",
        "# ==================================================\n",
        "# STRATEGY 1: SIMPLIFIED DIRECT STRUCTURE\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\nüéØ STRATEGY 1: SIMPLIFIED DIRECT STRUCTURE\")\n",
        "\n",
        "# Create a simpler, more direct network\n",
        "simple_model = DiscreteBayesianNetwork([\n",
        "    # Direct influences on efficiency\n",
        "    ('Shooting_FG', 'Efficiency'),\n",
        "    ('Shooting_3PT', 'Efficiency'),\n",
        "    ('Playmaking', 'Efficiency'),\n",
        "    ('Turnovers', 'Efficiency'),\n",
        "    ('Offensive_Rebounding', 'Efficiency'),\n",
        "    ('Defensive_Rebounding', 'Efficiency')\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Simple direct structure created\")\n",
        "\n",
        "# Learn CPTs with Bayesian estimation\n",
        "simple_model.fit(final_data, estimator=BayesianEstimator, prior_type='BDeu', equivalent_sample_size=5)\n",
        "print(\"‚úÖ CPTs learned with Bayesian estimation\")\n",
        "\n",
        "# Create inference engine\n",
        "inference_simple = VariableElimination(simple_model)\n",
        "\n",
        "# Test accuracy\n",
        "print(\"\\nüìä TESTING SIMPLE MODEL ACCURACY...\")\n",
        "predictions_simple = []\n",
        "true_labels = []\n",
        "\n",
        "for idx, row in final_data.iterrows():\n",
        "    evidence = {col: row[col] for col in final_data.columns if col != 'Efficiency'}\n",
        "    try:\n",
        "        result = inference_simple.query(variables=['Efficiency'], evidence=evidence)\n",
        "        predicted = result.state_names['Efficiency'][np.argmax(result.values)]\n",
        "        predictions_simple.append(predicted)\n",
        "        true_labels.append(row['Efficiency'])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "accuracy_simple = accuracy_score(true_labels, predictions_simple)\n",
        "print(f\"üéØ SIMPLE MODEL ACCURACY: {accuracy_simple:.1%}\")\n",
        "\n",
        "# ==================================================\n",
        "# STRATEGY 2: CAUSAL CHAIN STRUCTURE\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\nüéØ STRATEGY 2: CAUSAL CHAIN STRUCTURE\")\n",
        "\n",
        "# Create causal chain: Shooting ‚Üí Ball Handling ‚Üí Rebounding ‚Üí Efficiency\n",
        "causal_model = DiscreteBayesianNetwork([\n",
        "    # Shooting influences\n",
        "    ('Shooting_FG', 'Shooting_3PT'),  # Good shooters tend to be good at both\n",
        "\n",
        "    # Ball handling chain\n",
        "    ('Playmaking', 'Turnovers'),      # More playmaking can lead to more turnovers\n",
        "    ('Turnovers', 'Efficiency'),      # Turnovers directly hurt efficiency\n",
        "\n",
        "    # Rebounding influences\n",
        "    ('Offensive_Rebounding', 'Defensive_Rebounding'),  # Good rebounders do both\n",
        "\n",
        "    # Direct efficiency influences\n",
        "    ('Shooting_FG', 'Efficiency'),\n",
        "    ('Shooting_3PT', 'Efficiency'),\n",
        "    ('Playmaking', 'Efficiency'),\n",
        "    ('Offensive_Rebounding', 'Efficiency'),\n",
        "    ('Defensive_Rebounding', 'Efficiency')\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Causal chain structure created\")\n",
        "\n",
        "# Learn CPTs\n",
        "causal_model.fit(final_data, estimator=BayesianEstimator, prior_type='BDeu', equivalent_sample_size=5)\n",
        "print(\"‚úÖ CPTs learned\")\n",
        "\n",
        "# Test accuracy\n",
        "inference_causal = VariableElimination(causal_model)\n",
        "\n",
        "predictions_causal = []\n",
        "for idx, row in final_data.iterrows():\n",
        "    evidence = {col: row[col] for col in final_data.columns if col != 'Efficiency'}\n",
        "    try:\n",
        "        result = inference_causal.query(variables=['Efficiency'], evidence=evidence)\n",
        "        predicted = result.state_names['Efficiency'][np.argmax(result.values)]\n",
        "        predictions_causal.append(predicted)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "accuracy_causal = accuracy_score(true_labels[:len(predictions_causal)], predictions_causal)\n",
        "print(f\"üéØ CAUSAL MODEL ACCURACY: {accuracy_causal:.1%}\")\n",
        "\n",
        "# ==================================================\n",
        "# STRATEGY 3: ENSEMBLE APPROACH\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\nüéØ STRATEGY 3: ENSEMBLE PREDICTION\")\n",
        "\n",
        "def ensemble_predict(row, models, inferences):\n",
        "    predictions = []\n",
        "\n",
        "    for model, inference in zip(models, inferences):\n",
        "        evidence = {col: row[col] for col in final_data.columns if col != 'Efficiency'}\n",
        "        try:\n",
        "            result = inference.query(variables=['Efficiency'], evidence=evidence)\n",
        "            predicted = result.state_names['Efficiency'][np.argmax(result.values)]\n",
        "            predictions.append(predicted)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Return most frequent prediction\n",
        "    if predictions:\n",
        "        return max(set(predictions), key=predictions.count)\n",
        "    else:\n",
        "        return 'Medium'  # Default\n",
        "\n",
        "# Create ensemble\n",
        "models = [simple_model, causal_model]\n",
        "inferences = [inference_simple, inference_causal]\n",
        "\n",
        "ensemble_predictions = []\n",
        "for idx, row in final_data.iterrows():\n",
        "    pred = ensemble_predict(row, models, inferences)\n",
        "    ensemble_predictions.append(pred)\n",
        "\n",
        "accuracy_ensemble = accuracy_score(true_labels, ensemble_predictions)\n",
        "print(f\"üéØ ENSEMBLE ACCURACY: {accuracy_ensemble:.1%}\")\n",
        "\n",
        "# ==================================================\n",
        "# FINAL RESULTS & ANALYSIS\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"üìä Dataset Size: {len(final_data):,} samples\")\n",
        "print(f\"üéØ Simple Direct Model: {accuracy_simple:.1%}\")\n",
        "print(f\"üéØ Causal Chain Model: {accuracy_causal:.1%}\")\n",
        "print(f\"üéØ Ensemble Model: {accuracy_ensemble:.1%}\")\n",
        "\n",
        "# Find best model\n",
        "accuracies = {\n",
        "    'Simple Direct': accuracy_simple,\n",
        "    'Causal Chain': accuracy_causal,\n",
        "    'Ensemble': accuracy_ensemble\n",
        "}\n",
        "\n",
        "best_model_name = max(accuracies, key=accuracies.get)\n",
        "best_accuracy = accuracies[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name} ({best_accuracy:.1%})\")\n",
        "\n",
        "if best_accuracy > 0.54:\n",
        "    improvement = (best_accuracy - 0.54) * 100\n",
        "    print(f\"‚úÖ IMPROVEMENT: +{improvement:.1f}% over previous approach!\")\n",
        "\n",
        "# Detailed performance analysis\n",
        "print(f\"\\nüìà DETAILED PERFORMANCE (Best Model):\")\n",
        "if best_model_name == 'Simple Direct':\n",
        "    best_predictions = predictions_simple\n",
        "elif best_model_name == 'Causal Chain':\n",
        "    best_predictions = predictions_causal\n",
        "else:\n",
        "    best_predictions = ensemble_predictions\n",
        "\n",
        "print(classification_report(true_labels, best_predictions, target_names=['Low', 'Medium', 'High']))\n",
        "\n",
        "# ==================================================\n",
        "# BASKETBALL INSIGHTS\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\nüèÄ BASKETBALL INSIGHTS FROM BEST MODEL:\")\n",
        "\n",
        "# Test championship scenario\n",
        "print(\"\\n‚≠ê CHAMPIONSHIP TEAM ANALYSIS:\")\n",
        "champ_evidence = {\n",
        "    'Shooting_FG': 'High', 'Shooting_3PT': 'High',\n",
        "    'Playmaking': 'High', 'Turnovers': 'Low',\n",
        "    'Offensive_Rebounding': 'High', 'Defensive_Rebounding': 'High'\n",
        "}\n",
        "\n",
        "if best_model_name == 'Simple Direct':\n",
        "    result = inference_simple.query(variables=['Efficiency'], evidence=champ_evidence)\n",
        "elif best_model_name == 'Causal Chain':\n",
        "    result = inference_causal.query(variables=['Efficiency'], evidence=champ_evidence)\n",
        "else:\n",
        "    # Use simple model for insight generation\n",
        "    result = inference_simple.query(variables=['Efficiency'], evidence=champ_evidence)\n",
        "\n",
        "print(\"Elite team probabilities:\")\n",
        "for state, prob in zip(result.state_names['Efficiency'], result.values):\n",
        "    print(f\"  P(Efficiency = {state}): {prob:.3f}\")\n",
        "\n",
        "# Feature importance analysis\n",
        "print(\"\\nüîç FEATURE IMPORTANCE ANALYSIS:\")\n",
        "base_case = {col: 'Medium' for col in final_data.columns if col != 'Efficiency'}\n",
        "\n",
        "for feature in ['Shooting_FG', 'Shooting_3PT', 'Playmaking', 'Turnovers']:\n",
        "    # Test improvement when feature goes from Low to High\n",
        "    evidence_low = base_case.copy()\n",
        "    evidence_low[feature] = 'Low'\n",
        "\n",
        "    evidence_high = base_case.copy()\n",
        "    evidence_high[feature] = 'High'\n",
        "\n",
        "    if best_model_name == 'Simple Direct':\n",
        "        result_low = inference_simple.query(variables=['Efficiency'], evidence=evidence_low)\n",
        "        result_high = inference_simple.query(variables=['Efficiency'], evidence=evidence_high)\n",
        "    else:\n",
        "        result_low = inference_causal.query(variables=['Efficiency'], evidence=evidence_low)\n",
        "        result_high = inference_causal.query(variables=['Efficiency'], evidence=evidence_high)\n",
        "\n",
        "    p_high_low = result_low.values[result_low.state_names['Efficiency'].index('High')]\n",
        "    p_high_high = result_high.values[result_high.state_names['Efficiency'].index('High')]\n",
        "\n",
        "    improvement = p_high_high - p_high_low\n",
        "    print(f\"  {feature}: +{improvement:.3f} P(High) when going from Low‚ÜíHigh\")\n",
        "\n",
        "print(f\"\\nüéâ OPTIMIZATION COMPLETE!\")\n",
        "print(f\"üöÄ Best model achieves {best_accuracy:.1%} accuracy\")\n",
        "print(\"üí° Ready for deployment and further analysis!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nZdIWjqEMjdu",
        "outputId": "9ba112fc-87b9-46e7-9396-97a05462d6fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: nba_api in /usr/local/lib/python3.12/dist-packages (1.10.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.16.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pgmpy) (2.8.0+cu126)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pgmpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pgmpy) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.5.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from nba_api) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2025.10.5)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl->pgmpy) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pgmpy) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pgmpy) (3.0.3)\n",
            "‚úÖ Packages imported successfully!\n",
            "üöÄ GETTING REAL NBA LINEUP DATA FROM OFFICIAL NBA API...\n",
            "‚úÖ Found 30 NBA teams\n",
            "\n",
            "üì• DOWNLOADING LINEUP DATA FOR ALL TEAMS...\n",
            "   1/30: Getting Atlanta Hawks...\n",
            "   2/30: Getting Boston Celtics...\n",
            "   3/30: Getting Cleveland Cavaliers...\n",
            "   4/30: Getting New Orleans Pelicans...\n",
            "   5/30: Getting Chicago Bulls...\n",
            "   6/30: Getting Dallas Mavericks...\n",
            "   7/30: Getting Denver Nuggets...\n",
            "   8/30: Getting Golden State Warriors...\n",
            "   9/30: Getting Houston Rockets...\n",
            "   10/30: Getting Los Angeles Clippers...\n",
            "   11/30: Getting Los Angeles Lakers...\n",
            "   12/30: Getting Miami Heat...\n",
            "   13/30: Getting Milwaukee Bucks...\n",
            "   14/30: Getting Minnesota Timberwolves...\n",
            "   15/30: Getting Brooklyn Nets...\n",
            "   16/30: Getting New York Knicks...\n",
            "   17/30: Getting Orlando Magic...\n",
            "   18/30: Getting Indiana Pacers...\n",
            "   19/30: Getting Philadelphia 76ers...\n",
            "   20/30: Getting Phoenix Suns...\n",
            "   21/30: Getting Portland Trail Blazers...\n",
            "   22/30: Getting Sacramento Kings...\n",
            "   23/30: Getting San Antonio Spurs...\n",
            "   24/30: Getting Oklahoma City Thunder...\n",
            "   25/30: Getting Toronto Raptors...\n",
            "   26/30: Getting Utah Jazz...\n",
            "   27/30: Getting Memphis Grizzlies...\n",
            "   28/30: Getting Washington Wizards...\n",
            "   29/30: Getting Detroit Pistons...\n",
            "   30/30: Getting Charlotte Hornets...\n",
            "\n",
            "‚úÖ SUCCESS: Downloaded 7500 lineup combinations!\n",
            "\n",
            "üîç SAMPLE OF REAL NBA LINEUP DATA:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          GROUP_NAME           team  \\\n",
              "0  C. Capela - D. Murray - T. Young - S. Bey - J....  Atlanta Hawks   \n",
              "1  C. Capela - D. Murray - T. Young - D. Hunter -...  Atlanta Hawks   \n",
              "2  C. Capela - D. Murray - T. Young - D. Hunter -...  Atlanta Hawks   \n",
              "\n",
              "          MIN  PLUS_MINUS  FG_PCT  FG3_PCT  \n",
              "0  288.680000       -88.0   0.446    0.312  \n",
              "1  176.911667         8.0   0.468    0.384  \n",
              "2  171.505000       -26.0   0.464    0.367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9026024-0777-49fb-9fa9-c999cc7479fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GROUP_NAME</th>\n",
              "      <th>team</th>\n",
              "      <th>MIN</th>\n",
              "      <th>PLUS_MINUS</th>\n",
              "      <th>FG_PCT</th>\n",
              "      <th>FG3_PCT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C. Capela - D. Murray - T. Young - S. Bey - J....</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>288.680000</td>\n",
              "      <td>-88.0</td>\n",
              "      <td>0.446</td>\n",
              "      <td>0.312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C. Capela - D. Murray - T. Young - D. Hunter -...</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>176.911667</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C. Capela - D. Murray - T. Young - D. Hunter -...</td>\n",
              "      <td>Atlanta Hawks</td>\n",
              "      <td>171.505000</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9026024-0777-49fb-9fa9-c999cc7479fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9026024-0777-49fb-9fa9-c999cc7479fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9026024-0777-49fb-9fa9-c999cc7479fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-241e9ad8-cd85-4023-85f9-a0ac2a61c0b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-241e9ad8-cd85-4023-85f9-a0ac2a61c0b2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-241e9ad8-cd85-4023-85f9-a0ac2a61c0b2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\ud83d\\udca1 Ready for deployment and further analysis!\\\")\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"GROUP_NAME\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"C. Capela - D. Murray - T. Young - S. Bey - J. Johnson\",\n          \"C. Capela - D. Murray - T. Young - D. Hunter - S. Bey\",\n          \"C. Capela - D. Murray - T. Young - D. Hunter - J. Johnson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Atlanta Hawks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66.14551248906683,\n        \"min\": 171.505,\n        \"max\": 288.68,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          288.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PLUS_MINUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48.67579823005816,\n        \"min\": -88.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -88.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FG_PCT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01171893055416464,\n        \"min\": 0.446,\n        \"max\": 0.468,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FG3_PCT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03763420430052074,\n        \"min\": 0.312,\n        \"max\": 0.384,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== PHASE 2: OPTIMIZED DATA PROCESSING ===\n",
            "üìä Original data shape: (7500, 59)\n",
            "üìä Advanced features shape: (7500, 7)\n",
            "\n",
            "üìä FEATURE CORRELATIONS WITH EFFICIENCY:\n",
            "   Shooting_FG: 0.329\n",
            "   Playmaking: 0.274\n",
            "   Defensive_Rebounding: 0.243\n",
            "   Shooting_3PT: 0.223\n",
            "   Offensive_Rebounding: 0.022\n",
            "   Turnovers: -0.141\n",
            "\n",
            "üîß SMART DISCRETIZATION WITH QUANTILES...\n",
            "üìä Discretized data shape: (7500, 7)\n",
            "\n",
            "üìä DISCRETIZED DISTRIBUTION:\n",
            "Efficiency: {'Low': np.float64(0.35306666666666664), 'Medium': np.float64(0.3368), 'High': np.float64(0.3101333333333333)}\n",
            "Shooting_FG: {'Low': np.float64(0.3374666666666667), 'High': np.float64(0.3333333333333333), 'Medium': np.float64(0.3292)}\n",
            "Shooting_3PT: {'Low': np.float64(0.3456), 'High': np.float64(0.3284), 'Medium': np.float64(0.326)}\n",
            "Playmaking: {'Medium': np.float64(0.3336), 'Low': np.float64(0.3334666666666667), 'High': np.float64(0.33293333333333336)}\n",
            "Turnovers: {'Low': np.float64(0.3333333333333333), 'Medium': np.float64(0.3333333333333333), 'High': np.float64(0.3333333333333333)}\n",
            "Offensive_Rebounding: {'Medium': np.float64(0.3337333333333333), 'Low': np.float64(0.3333333333333333), 'High': np.float64(0.33293333333333336)}\n",
            "Defensive_Rebounding: {'Medium': np.float64(0.3337333333333333), 'Low': np.float64(0.3333333333333333), 'High': np.float64(0.33293333333333336)}\n",
            "üíæ Saved optimized data\n",
            "\n",
            "=== PHASE 3: OPTIMIZED BAYESIAN NETWORK ===\n",
            "üìä Training data: (7500, 7)\n",
            "\n",
            "üéØ STRATEGY 1: SIMPLIFIED DIRECT STRUCTURE\n",
            "‚úÖ Simple direct structure created\n",
            "‚úÖ CPTs learned with Bayesian estimation\n",
            "\n",
            "üìä TESTING SIMPLE MODEL ACCURACY...\n",
            "üéØ SIMPLE MODEL ACCURACY: 64.1%\n",
            "\n",
            "üéØ STRATEGY 2: CAUSAL CHAIN STRUCTURE\n",
            "‚úÖ Causal chain structure created\n",
            "‚úÖ CPTs learned\n",
            "üéØ CAUSAL MODEL ACCURACY: 64.1%\n",
            "\n",
            "üéØ STRATEGY 3: ENSEMBLE PREDICTION\n",
            "üéØ ENSEMBLE ACCURACY: 64.1%\n",
            "\n",
            "==================================================\n",
            "FINAL RESULTS SUMMARY\n",
            "==================================================\n",
            "üìä Dataset Size: 7,500 samples\n",
            "üéØ Simple Direct Model: 64.1%\n",
            "üéØ Causal Chain Model: 64.1%\n",
            "üéØ Ensemble Model: 64.1%\n",
            "\n",
            "üèÜ BEST MODEL: Simple Direct (64.1%)\n",
            "‚úÖ IMPROVEMENT: +10.1% over previous approach!\n",
            "\n",
            "üìà DETAILED PERFORMANCE (Best Model):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Low       0.66      0.73      0.69      2326\n",
            "      Medium       0.67      0.75      0.71      2648\n",
            "        High       0.57      0.45      0.50      2526\n",
            "\n",
            "    accuracy                           0.64      7500\n",
            "   macro avg       0.63      0.64      0.63      7500\n",
            "weighted avg       0.63      0.64      0.63      7500\n",
            "\n",
            "\n",
            "üèÄ BASKETBALL INSIGHTS FROM BEST MODEL:\n",
            "\n",
            "‚≠ê CHAMPIONSHIP TEAM ANALYSIS:\n",
            "Elite team probabilities:\n",
            "  P(Efficiency = High): 0.850\n",
            "  P(Efficiency = Low): 0.000\n",
            "  P(Efficiency = Medium): 0.150\n",
            "\n",
            "üîç FEATURE IMPORTANCE ANALYSIS:\n",
            "  Shooting_FG: +0.462 P(High) when going from Low‚ÜíHigh\n",
            "  Shooting_3PT: +0.160 P(High) when going from Low‚ÜíHigh\n",
            "  Playmaking: +0.349 P(High) when going from Low‚ÜíHigh\n",
            "  Turnovers: +-0.363 P(High) when going from Low‚ÜíHigh\n",
            "\n",
            "üéâ OPTIMIZATION COMPLETE!\n",
            "üöÄ Best model achieves 64.1% accuracy\n",
            "üí° Ready for deployment and further analysis!\n"
          ]
        }
      ]
    }
  ]
}